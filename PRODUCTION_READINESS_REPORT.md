# ØªÙ‚Ø±ÙŠØ± Ø¬Ø§Ù‡Ø²ÙŠØ© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù„Ù„Ø¥Ù†ØªØ§Ø¬ (Production Readiness Report)
## Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª

**ØªØ§Ø±ÙŠØ® Ø§Ù„ØªÙ‚Ø±ÙŠØ±:** 10 Ù†ÙˆÙÙ…Ø¨Ø± 2025  
**Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ:** v2.0  
**Ø§Ù„Ù„ØºØ©:** Python  
**Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©:** Streamlit, FastAPI, PostgreSQL

---

## Ù…Ù„Ø®Øµ ØªÙ†ÙÙŠØ°ÙŠ

Ù‡Ø°Ø§ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù‡Ùˆ ÙˆÙƒÙŠÙ„ Ø°ÙƒÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Gemini/Groq). Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ù…Ø¨Ù†ÙŠ Ø¨Ù„ØºØ© Python ÙˆÙŠØ³ØªØ®Ø¯Ù… Streamlit Ù„Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø£Ù…Ø§Ù…ÙŠØ© Ùˆ FastAPI Ù„Ù€ REST API. 

**Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ©:** Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ÙÙŠ Ù…Ø±Ø­Ù„Ø© ØªØ·ÙˆÙŠØ± Ù…ØªÙ‚Ø¯Ù…Ø© (Development Stage) ÙˆÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ ØªØ­Ø³ÙŠÙ†Ø§Øª Ø¬ÙˆÙ‡Ø±ÙŠØ© Ù‚Ø¨Ù„ Ø§Ù„Ù†Ø´Ø± ÙÙŠ Ø¨ÙŠØ¦Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬.

**Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø¬Ø§Ù‡Ø²ÙŠØ©:** 40% Ù…Ù† Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø¥Ù†ØªØ§Ø¬

---

## ğŸ“‹ Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª

1. [Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„ØªÙ‚Ù†ÙŠ (Technical Audit)](#1-Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚-Ø§Ù„ØªÙ‚Ù†ÙŠ)
2. [Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¬ÙˆØ¯Ø© ÙˆØ§Ù„Ø£Ù…Ø§Ù†](#2-Ù…Ø¹Ø§ÙŠÙŠØ±-Ø§Ù„Ø¬ÙˆØ¯Ø©-ÙˆØ§Ù„Ø£Ù…Ø§Ù†)
3. [Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ†](#3-Ø§Ù„Ø£Ø¯Ø§Ø¡-ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ†)
4. [Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØªØ­ØªÙŠØ© ÙˆØ§Ù„Ù†Ø´Ø±](#4-Ø§Ù„Ø¨Ù†ÙŠØ©-Ø§Ù„ØªØ­ØªÙŠØ©-ÙˆØ§Ù„Ù†Ø´Ø±)
5. [Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª](#5-Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª)
6. [Ø§Ù„ØªÙˆØ«ÙŠÙ‚](#6-Ø§Ù„ØªÙˆØ«ÙŠÙ‚)
7. [Ø®Ø·Ø© Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠØ©](#7-Ø®Ø·Ø©-Ø§Ù„Ø¹Ù…Ù„-Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠØ©)

---

## 1. Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„ØªÙ‚Ù†ÙŠ (Technical Audit)

### 1.1 ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù„Ù„Ù…Ø´Ø±ÙˆØ¹

#### âœ… **Ù†Ù‚Ø§Ø· Ø§Ù„Ù‚ÙˆØ©:**

**Ø¨Ù†ÙŠØ© Ù…Ø¹Ù…Ø§Ø±ÙŠØ© Ù…Ù†Ø¸Ù…Ø©:**
```
Ø§Ù„Ù…Ø´Ø±ÙˆØ¹/
â”œâ”€â”€ app.py                    # Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ (Streamlit)
â”œâ”€â”€ api.py                    # REST API (FastAPI)
â”œâ”€â”€ web_scraper.py           # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø­ØªÙˆÙ‰
â”œâ”€â”€ gemini_helper.py         # ØªÙƒØ§Ù…Ù„ Gemini API
â”œâ”€â”€ groq_helper.py           # ØªÙƒØ§Ù…Ù„ Groq API (Ø§Ø­ØªÙŠØ§Ø·ÙŠ)
â”œâ”€â”€ source_evaluator.py      # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…ØµØ§Ø¯Ø±
â”œâ”€â”€ image_processor.py       # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±
â”œâ”€â”€ video_processor.py       # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª
â”œâ”€â”€ database.py              # Ø¥Ø¯Ø§Ø±Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
â”œâ”€â”€ cache_manager.py         # Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù…Ø¤Ù‚Øª
â”œâ”€â”€ export_utils.py          # Ø§Ù„ØªØµØ¯ÙŠØ± (PDF, Word, Markdown)
â””â”€â”€ sharing_utils.py         # Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª
```

**Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…Ù†ÙØ°Ø©:**
- âœ… ÙˆØ§Ø¬Ù‡Ø© Ø¹Ø±Ø¨ÙŠØ© ØªÙØ§Ø¹Ù„ÙŠØ© Ù…Ø¹ Ø¯Ø¹Ù… RTL ÙƒØ§Ù…Ù„
- âœ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØªÙˆÙ‰ Ø°ÙƒÙŠ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Trafilatura Ùˆ BeautifulSoup
- âœ… ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ (Gemini/Groq)
- âœ… Ù†Ø¸Ø§Ù… Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù„Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¨ÙŠÙ† AI providers
- âœ… Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª PostgreSQL Ù„Ø­ÙØ¸ Ø§Ù„Ø³Ø¬Ù„
- âœ… Ù†Ø¸Ø§Ù… Caching Ù„Ù„Ø£Ø¯Ø§Ø¡
- âœ… REST API Ù…Ø¹ Swagger Documentation
- âœ… ØªØµØ¯ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª (PDF, Word, Markdown)
- âœ… Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ù…Ø¹ QR codes
- âœ… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª

#### âŒ **Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù Ø§Ù„Ø­Ø±Ø¬Ø©:**

##### 1. **Ø£Ø®Ø·Ø§Ø¡ Ø¨Ø±Ù…Ø¬ÙŠØ© (LSP Errors): 15 Ø®Ø·Ø£**

**Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ØªØ£Ø«Ø±Ø©:**
- `app.py`: 11 Ø®Ø·Ø£
- `api.py`: 2 Ø®Ø·Ø£  
- `web_scraper.py`: 1 Ø®Ø·Ø£
- `gemini_helper.py`: 1 Ø®Ø·Ø£

**Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡:**
```python
# app.py - Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªØ®Ø¯Ø§Ù… Column objects Ù…Ù† SQLAlchemy
if analysis.url:  # âŒ Invalid conditional operand
    # Ø§Ù„Ø­Ù„: ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ string Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… getattr
    if getattr(analysis, 'url', None):  # âœ…

# api.py - ØªÙ…Ø±ÙŠØ± Column object Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ù‚ÙŠÙ…Ø©
create_share_link(
    analysis_id=analysis.id,  # âŒ Column[int] Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† int
    url=analysis.url,          # âŒ Column[str] Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† str
)
```

**Ø§Ù„ØªØ£Ø«ÙŠØ±:** Ù‡Ø°Ù‡ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ù‚Ø¯ ØªØ³Ø¨Ø¨ ÙØ´Ù„ ÙÙŠ ÙˆÙ‚Øª Ø§Ù„ØªØ´ØºÙŠÙ„ (Runtime Errors).

##### 2. **ØºÙŠØ§Ø¨ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø£Ø®Ø·Ø§Ø¡**

```python
# âŒ Ù…Ø«Ø§Ù„ Ø­Ø§Ù„ÙŠ - Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ø¶Ø¹ÙŠÙØ©
try:
    content_data = extract_content_from_url(url_input)
except Exception as e:
    st.error(f"Ø®Ø·Ø£: {str(e)}")  # Ø±Ø³Ø§Ù„Ø© ØºÙŠØ± ÙˆØ§Ø¶Ø­Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…

# âœ… Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ - Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ù…ÙØµÙ„Ø©
try:
    content_data = extract_content_from_url(url_input)
except requests.RequestException as e:
    logger.error(f"Network error: {e}")
    st.error("âš ï¸ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù…ÙˆÙ‚Ø¹. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ÙˆØ­Ø§ÙˆÙ„ Ù…Ø¬Ø¯Ø¯Ø§Ù‹.")
except trafilatura.TrafilaturaException as e:
    logger.error(f"Parsing error: {e}")
    st.error("âš ï¸ ÙØ´Ù„ ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ØµÙØ­Ø©. Ù‚Ø¯ ÙŠÙƒÙˆÙ† Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ù…Ø­Ù…ÙŠ.")
except Exception as e:
    logger.critical(f"Unexpected error: {e}", exc_info=True)
    st.error("âš ï¸ Ø­Ø¯Ø« Ø®Ø·Ø£ ØºÙŠØ± Ù…ØªÙˆÙ‚Ø¹. ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©.")
```

##### 3. **ØºÙŠØ§Ø¨ Logging Ù…Ù†Ø¸Ù…**

```python
# âŒ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù†Ø¸Ø§Ù… logging Ø­Ø§Ù„ÙŠØ§Ù‹
# âœ… Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
import logging
from logging.handlers import RotatingFileHandler

# Ø¥Ø¹Ø¯Ø§Ø¯ Logger Ù…Ø±ÙƒØ²ÙŠ
logger = logging.getLogger('content_analyzer')
logger.setLevel(logging.INFO)

# Handler Ù„Ù„Ù…Ù„ÙØ§Øª Ù…Ø¹ Rotation
file_handler = RotatingFileHandler(
    'logs/app.log', 
    maxBytes=10485760,  # 10MB
    backupCount=5
)
file_handler.setFormatter(
    logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
)
logger.addHandler(file_handler)

# Ø§Ø³ØªØ®Ø¯Ø§Ù…
logger.info(f"Analysis started for URL: {url}")
logger.error(f"Failed to extract content: {error}")
```

### 1.2 Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ÙŠØ§Øª (Dependencies)

#### **Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©:** (23 Ù…ÙƒØªØ¨Ø©)

```toml
[project.dependencies]
arabic-reshaper>=3.0.0
beautifulsoup4>=4.14.2
fastapi>=0.121.1
google-genai>=1.49.0
groq>=0.33.0
langdetect>=1.0.9
lxml>=6.0.2
markdown>=3.10
markdownify>=1.2.0
pillow>=12.0.0
psycopg2-binary>=2.9.11
pydantic>=2.12.4
python-bidi>=0.6.7
python-docx>=1.2.0
qrcode>=8.2
reportlab>=4.4.4
requests>=2.32.5
sift-stack-py>=0.9.1
sqlalchemy>=2.0.44
streamlit>=1.51.0
trafilatura>=2.0.0
uvicorn>=0.38.0
youtube-transcript-api>=1.2.3
yt-dlp>=2025.10.22
```

#### âš ï¸ **Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ÙŠØ§Øª:**

1. **Ø¥ØµØ¯Ø§Ø±Ø§Øª Ù…ÙØªÙˆØ­Ø© (`>=`)**: Ø®Ø·Ø± Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„ÙƒØ³Ø±ÙŠØ© (Breaking Changes)
   ```toml
   # âŒ Ù…Ø´ÙƒÙ„Ø©
   streamlit>=1.51.0  # Ù‚Ø¯ ÙŠØªØ­Ø¯Ø« Ø¥Ù„Ù‰ 2.0.0 Ù…Ø¹ breaking changes
   
   # âœ… Ø­Ù„
   streamlit>=1.51.0,<2.0.0  # ØªØ­Ø¯ÙŠØ¯ Ù†Ø·Ø§Ù‚ Ø¢Ù…Ù†
   ```

2. **ØºÙŠØ§Ø¨ Ù…Ù„Ù `requirements.txt` Ù…Ø­Ø¯Ø¯ Ù„Ù„Ø¥Ù†ØªØ§Ø¬**
   ```bash
   # âœ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„ÙØ§Øª Ù…Ù†ÙØµÙ„Ø©
   requirements/
   â”œâ”€â”€ base.txt           # Ø§Ø¹ØªÙ…Ø§Ø¯ÙŠØ§Øª Ø£Ø³Ø§Ø³ÙŠØ©
   â”œâ”€â”€ development.txt    # Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ·ÙˆÙŠØ±
   â”œâ”€â”€ production.txt     # Ø§Ù„Ø¥Ù†ØªØ§Ø¬ ÙÙ‚Ø·
   â””â”€â”€ testing.txt        # Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
   ```

3. **ØºÙŠØ§Ø¨ ÙØ­Øµ Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ©**
   ```bash
   # âœ… Ø¥Ø¶Ø§ÙØ© ÙØ­Øµ Ø¯ÙˆØ±ÙŠ
   pip install safety
   safety check --json > security-report.json
   ```

#### ğŸ“ **Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ù„Ù„Ø¥Ù†ØªØ§Ø¬:**

```toml
# Monitoring & Logging
prometheus-client>=0.19.0
python-json-logger>=2.0.7
sentry-sdk>=1.40.0

# Security
python-jose[cryptography]>=3.3.0
passlib[bcrypt]>=1.7.4
python-multipart>=0.0.6

# Performance
redis>=5.0.0
celery>=5.3.0

# Testing (Ù…ÙÙ‚ÙˆØ¯ ØªÙ…Ø§Ù…Ø§Ù‹!)
pytest>=7.4.3
pytest-cov>=4.1.0
pytest-asyncio>=0.21.1
httpx>=0.25.2
faker>=20.1.0

# Rate Limiting
slowapi>=0.1.9

# Environment Management
python-dotenv>=1.0.0

# Database Migrations
alembic>=1.13.0
```

### 1.3 Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ© Ø§Ù„Ø­Ø±Ø¬Ø©

#### ğŸ”´ **Ù…Ø³ØªÙˆÙ‰ Ø¹Ø§Ù„ÙŠ (High Severity):**

##### 1. **CORS Ù…ÙØªÙˆØ­ ØªÙ…Ø§Ù…Ø§Ù‹**
```python
# api.py - Line 36
# âŒ Ø®Ø·Ø± Ø£Ù…Ù†ÙŠ Ø­Ø±Ø¬
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],        # ÙŠØ³Ù…Ø­ Ù„Ø£ÙŠ Ù…ÙˆÙ‚Ø¹!
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# âœ… Ø§Ù„Ø­Ù„
ALLOWED_ORIGINS = [
    "https://yourdomain.com",
    "https://www.yourdomain.com",
]

# ÙÙŠ Ø§Ù„ØªØ·ÙˆÙŠØ± ÙÙ‚Ø·
if os.environ.get("ENVIRONMENT") == "development":
    ALLOWED_ORIGINS.append("http://localhost:3000")

app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["GET", "POST", "PUT", "DELETE"],
    allow_headers=["Content-Type", "Authorization"],
)
```

##### 2. **ØºÙŠØ§Ø¨ Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø© ÙˆØ§Ù„ØªÙÙˆÙŠØ¶ (Authentication & Authorization)**

```python
# âŒ Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© - API Ø¹Ø§Ù… Ø¨Ø¯ÙˆÙ† Ø­Ù…Ø§ÙŠØ©
@app.post("/analyze")
async def analyze_content(request: AnalysisRequest):
    # Ø£ÙŠ Ø´Ø®Øµ ÙŠÙ…ÙƒÙ†Ù‡ Ø§Ù„ÙˆØµÙˆÙ„!
    pass

# âœ… Ø§Ù„Ø­Ù„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
from fastapi import Depends, HTTPException, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials

security = HTTPBearer()

async def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
    token = credentials.credentials
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† JWT token
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
        return payload
    except jwt.JWTError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid authentication credentials"
        )

@app.post("/analyze")
async def analyze_content(
    request: AnalysisRequest,
    user = Depends(verify_token)  # âœ… ÙŠØªØ·Ù„Ø¨ Ù…ØµØ§Ø¯Ù‚Ø©
):
    pass
```

##### 3. **ØºÙŠØ§Ø¨ Rate Limiting**

```python
# âŒ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©: ÙŠÙ…ÙƒÙ† Ù„Ø£ÙŠ Ø´Ø®Øµ Ø¥Ø±Ø³Ø§Ù„ Ø¢Ù„Ø§Ù Ø§Ù„Ø·Ù„Ø¨Ø§Øª
# Ø§Ù„ØªØ£Ø«ÙŠØ±: Ø§Ø³ØªÙ†Ø²Ø§Ù API quota Ù„Ù€ Gemini/GroqØŒ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªÙƒØ§Ù„ÙŠÙ

# âœ… Ø§Ù„Ø­Ù„
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@app.post("/analyze")
@limiter.limit("5/minute")  # 5 Ø·Ù„Ø¨Ø§Øª ÙÙŠ Ø§Ù„Ø¯Ù‚ÙŠÙ‚Ø©
async def analyze_content(request: Request, data: AnalysisRequest):
    pass
```

##### 4. **SQL Injection (Ù…Ù†Ø®ÙØ¶ - Ù„ÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯)**

```python
# database.py - Ø§Ø³ØªØ®Ø¯Ø§Ù… SQLAlchemy ORM (âœ… Ø¬ÙŠØ¯)
# Ù„ÙƒÙ† ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø£Ù…Ø§ÙƒÙ† Ù‚Ø¯ ØªÙˆØ¬Ø¯ Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ù†ØµÙŠØ©

# âš ï¸ Ø§Ø­Ø°Ø± Ù…Ù†
# db.execute(f"SELECT * FROM users WHERE id = {user_id}")  # âŒ

# âœ… Ø§Ø³ØªØ®Ø¯Ù… Ø¯Ø§Ø¦Ù…Ø§Ù‹
# db.execute("SELECT * FROM users WHERE id = :id", {"id": user_id})  # âœ…
```

##### 5. **XSS (Cross-Site Scripting) ÙÙŠ Streamlit**

```python
# âŒ Ù…Ø´ÙƒÙ„Ø© Ù…Ø­ØªÙ…Ù„Ø©
st.markdown(f"**Ø§Ù„Ù†ØªÙŠØ¬Ø©:** {user_input}", unsafe_allow_html=True)

# âœ… Ø§Ù„Ø­Ù„
import html
safe_input = html.escape(user_input)
st.markdown(f"**Ø§Ù„Ù†ØªÙŠØ¬Ø©:** {safe_input}", unsafe_allow_html=True)
```

##### 6. **ØªØ®Ø²ÙŠÙ† API Keys Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ø¢Ù…Ù†**

```python
# âœ… Ø§Ù„Ø­Ø§Ù„ÙŠ (Ø¬ÙŠØ¯) - Ø§Ø³ØªØ®Ø¯Ø§Ù… Environment Variables
api_key = os.environ.get("GEMINI_API_KEY")

# âœ… ØªØ­Ø³ÙŠÙ† - Ø§Ø³ØªØ®Ø¯Ø§Ù… Secret Management
# Ù…Ù† AWS Secrets Manager, HashiCorp Vault, Ø¥Ù„Ø®
import boto3

def get_secret(secret_name):
    client = boto3.client('secretsmanager', region_name='us-east-1')
    response = client.get_secret_value(SecretId=secret_name)
    return json.loads(response['SecretString'])

api_key = get_secret('prod/gemini/api_key')['api_key']
```

### 1.4 ÙØ­Øµ Ø§Ù„Ø£Ø¯Ø§Ø¡ (Performance Audit)

#### **Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø§Ù„Ø­Ø§Ù„ÙŠØ©:**

##### 1. **Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªØ²Ø§Ù…Ù†Ø© (Synchronous Processing)**

```python
# âŒ Ø§Ù„Ù…Ø´ÙƒÙ„Ø© - ÙƒÙ„ Ø·Ù„Ø¨ ÙŠØ­Ø¬Ø¨ Ø§Ù„Ø¢Ø®Ø±ÙŠÙ†
def analyze_content_with_gemini(content: str, url: str):
    response = client.models.generate_content(...)  # ÙŠØ³ØªØºØ±Ù‚ 5-10 Ø«ÙˆØ§Ù†ÙŠ
    return response.text

# âœ… Ø§Ù„Ø­Ù„ - Ø§Ø³ØªØ®Ø¯Ø§Ù… Async/Await
async def analyze_content_with_gemini(content: str, url: str):
    response = await asyncio.to_thread(
        client.models.generate_content, ...
    )
    return response.text
```

##### 2. **ØºÙŠØ§Ø¨ Connection Pooling Ù„Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**

```python
# database.py - Ø§Ù„Ø­Ø§Ù„ÙŠ
engine = create_engine(DATABASE_URL)

# âœ… ØªØ­Ø³ÙŠÙ†
engine = create_engine(
    DATABASE_URL,
    pool_size=10,              # Ø¹Ø¯Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª Ø§Ù„Ø¯Ø§Ø¦Ù…Ø©
    max_overflow=20,           # Ø§ØªØµØ§Ù„Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©
    pool_pre_ping=True,        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø§ØªØµØ§Ù„
    pool_recycle=3600,         # Ø¥Ø¹Ø§Ø¯Ø© Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„Ø§Øª ÙƒÙ„ Ø³Ø§Ø¹Ø©
)
```

##### 3. **Caching Ù…Ø­Ø¯ÙˆØ¯**

```python
# âœ… Ø§Ù„Ø­Ø§Ù„ÙŠ (Ø¬ÙŠØ¯) - caching ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
_cache_store = {}

# âš ï¸ Ù…Ø´ÙƒÙ„Ø© - ÙŠÙÙÙ‚Ø¯ Ø¹Ù†Ø¯ Ø¥Ø¹Ø§Ø¯Ø© ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚

# âœ… ØªØ­Ø³ÙŠÙ† - Ø§Ø³ØªØ®Ø¯Ø§Ù… Redis
import redis

redis_client = redis.Redis(
    host='localhost',
    port=6379,
    db=0,
    decode_responses=True
)

def get_cache(key: str):
    return redis_client.get(key)

def set_cache(key: str, value: str, ttl: int = 3600):
    redis_client.setex(key, ttl, value)
```

##### 4. **Ø¹Ø¯Ù… Ø§Ø³ØªØ®Ø¯Ø§Ù… CDN Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø«Ø§Ø¨ØªØ©**

```markdown
# âœ… Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
- Ø±ÙØ¹ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙØµØ¯Ù‘Ø±Ø© Ø¥Ù„Ù‰ S3 Ø£Ùˆ Cloud Storage
- Ø§Ø³ØªØ®Ø¯Ø§Ù… CloudFront Ø£Ùˆ Cloudflare CDN
- ØªÙ‚Ø¯ÙŠÙ… PDF/Word exports Ù…Ù† CDN Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø®Ø§Ø¯Ù… Ù…Ø¨Ø§Ø´Ø±Ø©
```

---

## 2. Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ø¬ÙˆØ¯Ø© ÙˆØ§Ù„Ø£Ù…Ø§Ù†

### 2.1 ØªØ·Ø¨ÙŠÙ‚ Ø£ÙØ¶Ù„ Ù…Ù…Ø§Ø±Ø³Ø§Øª Python

#### âŒ **Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠØ©:**

##### 1. **ØºÙŠØ§Ø¨ Type Hints Ø§Ù„ÙƒØ§Ù…Ù„**

```python
# âŒ Ø§Ù„Ø­Ø§Ù„ÙŠ - Ø¨Ø¹Ø¶ Ø§Ù„Ø¯ÙˆØ§Ù„ Ø¨Ø¯ÙˆÙ† type hints
def process_data(data):
    return data.upper()

# âœ… Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
from typing import Optional, Dict, List

def process_data(data: str) -> str:
    return data.upper()

def extract_content_from_url(url: str) -> Dict[str, any]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø±Ø§Ø¨Ø·"""
    pass
```

##### 2. **ØºÙŠØ§Ø¨ Docstrings Ù…ÙˆØ­Ø¯**

```python
# âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Google Style Docstrings
def analyze_content_with_gemini(content: str, url: str, language: str = "ar") -> str:
    """
    ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini API.

    Args:
        content (str): Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù†ØµÙŠ Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ­Ù„ÙŠÙ„Ù‡
        url (str): Ø±Ø§Ø¨Ø· Ø§Ù„Ù…ØµØ¯Ø±
        language (str, optional): Ù„ØºØ© Ø§Ù„ØªØ­Ù„ÙŠÙ„. Defaults to "ar".

    Returns:
        str: Ù†Øµ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙÙ†Ø³Ù‘Ù‚ Ø¨Ù€ Markdown

    Raises:
        ValueError: Ø¥Ø°Ø§ ÙƒØ§Ù† GEMINI_API_KEY Ù…ÙÙ‚ÙˆØ¯
        Exception: Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ API

    Example:
        >>> analysis = analyze_content_with_gemini(
        ...     "Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„...",
        ...     "https://example.com"
        ... )
    """
    pass
```

##### 3. **Ø¹Ø¯Ù… Ø§Ø³ØªØ®Ø¯Ø§Ù… Linting Tools**

```bash
# âœ… Ø¥Ø¶Ø§ÙØ© Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø¬ÙˆØ¯Ø©
pip install black isort flake8 mypy pylint

# .flake8
[flake8]
max-line-length = 100
exclude = .git,__pycache__,venv
ignore = E203, W503

# pyproject.toml
[tool.black]
line-length = 100
target-version = ['py311']

[tool.isort]
profile = "black"
line_length = 100

[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
```

##### 4. **ØºÙŠØ§Ø¨ Pre-commit Hooks**

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/psf/black
    rev: 23.12.1
    hooks:
      - id: black

  - repo: https://github.com/pycqa/isort
    rev: 5.13.2
    hooks:
      - id: isort

  - repo: https://github.com/pycqa/flake8
    rev: 7.0.0
    hooks:
      - id: flake8

  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.8.0
    hooks:
      - id: mypy
        additional_dependencies: [types-requests]
```

### 2.2 Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø£Ø®Ø·Ø§Ø¡

#### **Ù†Ø¸Ø§Ù… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª:**

##### 1. **Custom Exceptions**

```python
# exceptions.py (Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯)
class ContentAnalyzerException(Exception):
    """Base exception for the application"""
    pass

class ExtractionError(ContentAnalyzerException):
    """Failed to extract content from URL"""
    pass

class AnalysisError(ContentAnalyzerException):
    """AI analysis failed"""
    pass

class DatabaseError(ContentAnalyzerException):
    """Database operation failed"""
    pass

class RateLimitError(ContentAnalyzerException):
    """API rate limit exceeded"""
    pass
```

##### 2. **Error Handler Middleware**

```python
# api.py
from fastapi import Request
from fastapi.responses import JSONResponse

@app.exception_handler(ContentAnalyzerException)
async def custom_exception_handler(request: Request, exc: ContentAnalyzerException):
    logger.error(f"{type(exc).__name__}: {str(exc)}")
    return JSONResponse(
        status_code=400,
        content={
            "error": type(exc).__name__,
            "message": str(exc),
            "timestamp": datetime.now().isoformat()
        }
    )
```

##### 3. **Retry Logic**

```python
# utils/retry.py
from functools import wraps
import time

def retry(max_attempts=3, delay=1, backoff=2, exceptions=(Exception,)):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            attempt = 0
            current_delay = delay
            
            while attempt < max_attempts:
                try:
                    return func(*args, **kwargs)
                except exceptions as e:
                    attempt += 1
                    if attempt >= max_attempts:
                        raise
                    
                    logger.warning(
                        f"Attempt {attempt} failed: {e}. "
                        f"Retrying in {current_delay}s..."
                    )
                    time.sleep(current_delay)
                    current_delay *= backoff
            
        return wrapper
    return decorator

# Ø§Ø³ØªØ®Ø¯Ø§Ù…
@retry(max_attempts=3, delay=2, exceptions=(requests.RequestException,))
def fetch_url(url: str):
    return requests.get(url, timeout=10)
```

### 2.3 ØªØ£Ù…ÙŠÙ† API Endpoints

#### **Ù†Ø¸Ø§Ù… Ø£Ù…Ø§Ù† Ù…ØªÙƒØ§Ù…Ù„:**

##### 1. **JWT Authentication**

```python
# auth.py (Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯)
from datetime import datetime, timedelta
from jose import JWTError, jwt
from passlib.context import CryptContext

SECRET_KEY = os.environ.get("JWT_SECRET_KEY", "your-secret-key-change-in-production")
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 30

pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

def create_access_token(data: dict, expires_delta: timedelta = None):
    to_encode = data.copy()
    expire = datetime.utcnow() + (expires_delta or timedelta(minutes=15))
    to_encode.update({"exp": expire})
    return jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)

def verify_token(token: str):
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        return payload
    except JWTError:
        return None
```

##### 2. **Role-Based Access Control (RBAC)**

```python
# permissions.py
from enum import Enum

class Role(str, Enum):
    ADMIN = "admin"
    USER = "user"
    GUEST = "guest"

class Permission(str, Enum):
    ANALYZE_CONTENT = "analyze:content"
    EXPORT_ANALYSIS = "export:analysis"
    DELETE_ANALYSIS = "delete:analysis"
    VIEW_STATS = "view:stats"

ROLE_PERMISSIONS = {
    Role.ADMIN: [p for p in Permission],
    Role.USER: [
        Permission.ANALYZE_CONTENT,
        Permission.EXPORT_ANALYSIS,
    ],
    Role.GUEST: [Permission.ANALYZE_CONTENT]
}

def has_permission(role: Role, permission: Permission) -> bool:
    return permission in ROLE_PERMISSIONS.get(role, [])
```

##### 3. **Input Validation & Sanitization**

```python
# validators.py
from pydantic import BaseModel, HttpUrl, validator, Field

class AnalysisRequestValidated(BaseModel):
    url: HttpUrl
    ai_provider: str = Field(default="gemini", regex="^(gemini|groq)$")
    analyze_images: bool = False
    analyze_video: bool = False
    
    @validator('url')
    def validate_url(cls, v):
        # ÙØ­Øµ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø³ÙˆØ¯Ø§Ø¡
        blocked_domains = ['malicious-site.com', 'spam.com']
        if any(domain in str(v) for domain in blocked_domains):
            raise ValueError('Ù‡Ø°Ø§ Ø§Ù„Ù…ÙˆÙ‚Ø¹ Ù…Ø­Ø¸ÙˆØ±')
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¨Ø±ÙˆØªÙˆÙƒÙˆÙ„
        if not str(v).startswith(('http://', 'https://')):
            raise ValueError('Ø§Ù„Ø±Ø§Ø¨Ø· ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ¨Ø¯Ø£ Ø¨Ù€ http:// Ø£Ùˆ https://')
        
        return v
    
    class Config:
        json_schema_extra = {
            "example": {
                "url": "https://example.com/article",
                "ai_provider": "gemini",
                "analyze_images": False
            }
        }
```

##### 4. **CSRF Protection**

```python
# csrf.py
from fastapi import Request, HTTPException
import secrets

def generate_csrf_token() -> str:
    return secrets.token_urlsafe(32)

async def verify_csrf_token(request: Request):
    token = request.headers.get("X-CSRF-Token")
    stored_token = request.session.get("csrf_token")
    
    if not token or token != stored_token:
        raise HTTPException(status_code=403, detail="CSRF validation failed")
```

### 2.4 Ø¥Ø¯Ø§Ø±Ø© Ø¢Ù…Ù†Ø© Ù„Ù„Ù€ Secrets

#### **Ù†Ø¸Ø§Ù… Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø³Ø±Ø§Ø±:**

##### 1. **Environment Variables Structure**

```bash
# .env.example
# API Keys
GEMINI_API_KEY=your_gemini_key_here
GROQ_API_KEY=your_groq_key_here

# Database
DATABASE_URL=postgresql://user:password@localhost:5432/dbname

# Security
JWT_SECRET_KEY=your_jwt_secret_here
ENCRYPTION_KEY=your_encryption_key_here

# Application
ENVIRONMENT=development
LOG_LEVEL=INFO
ALLOWED_ORIGINS=https://yourdomain.com

# Rate Limiting
RATE_LIMIT_PER_MINUTE=60
RATE_LIMIT_PER_HOUR=1000

# Cache
REDIS_URL=redis://localhost:6379/0
CACHE_TTL=3600

# External Services
SENTRY_DSN=your_sentry_dsn_here
```

##### 2. **Secrets Rotation**

```python
# secrets_manager.py
import boto3
from datetime import datetime, timedelta

class SecretsManager:
    def __init__(self):
        self.client = boto3.client('secretsmanager')
    
    def get_secret(self, secret_name: str) -> dict:
        try:
            response = self.client.get_secret_value(SecretId=secret_name)
            return json.loads(response['SecretString'])
        except Exception as e:
            logger.error(f"Failed to retrieve secret: {e}")
            raise
    
    def rotate_secret(self, secret_name: str):
        """Rotate secret automatically"""
        try:
            self.client.rotate_secret(SecretId=secret_name)
            logger.info(f"Secret {secret_name} rotated successfully")
        except Exception as e:
            logger.error(f"Failed to rotate secret: {e}")
            raise
```

##### 3. **Secrets Validation**

```python
# startup.py
def validate_required_secrets():
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ø³Ø±Ø§Ø± Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ø¹Ù†Ø¯ Ø¨Ø¯Ø¡ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚"""
    required_secrets = [
        "GEMINI_API_KEY",
        "DATABASE_URL",
        "JWT_SECRET_KEY",
    ]
    
    missing = []
    for secret in required_secrets:
        if not os.environ.get(secret):
            missing.append(secret)
    
    if missing:
        raise RuntimeError(
            f"Missing required environment variables: {', '.join(missing)}"
        )
    
    logger.info("âœ… All required secrets are present")

# ÙÙŠ app.py Ùˆ api.py
validate_required_secrets()
```

---

## 3. Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ† (Performance Optimization)

### 3.1 ØªØ­Ø³ÙŠÙ† Ø­Ø¬Ù… Ø§Ù„Ø­Ø²Ù… (Bundle Size Optimization)

#### **ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ:**

```bash
# ØªØ­Ù„ÙŠÙ„ Ø­Ø¬Ù… Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª
pip install pipdeptree
pipdeptree --graph-output png > dependencies.png

# Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠ: ~500MB
```

#### **Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ†:**

##### 1. **Docker Multi-Stage Build**

```dockerfile
# Dockerfile
# Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø§Ù„Ø¨Ù†Ø§Ø¡
FROM python:3.11-slim as builder

WORKDIR /app

# ØªØ«Ø¨ÙŠØª Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ÙŠØ§Øª ÙÙ‚Ø·
COPY requirements.txt .
RUN pip install --no-cache-dir --user -r requirements.txt

# Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø§Ù„Ø¥Ù†ØªØ§Ø¬ (Ø£ØµØºØ±)
FROM python:3.11-slim

WORKDIR /app

# Ù†Ø³Ø® Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ù…Ù† Ù…Ø±Ø­Ù„Ø© Ø§Ù„Ø¨Ù†Ø§Ø¡
COPY --from=builder /root/.local /root/.local

# Ù†Ø³Ø® Ø§Ù„ÙƒÙˆØ¯ ÙÙ‚Ø·
COPY . .

# ØªØ­Ø¯ÙŠØ« PATH
ENV PATH=/root/.local/bin:$PATH

# Ø§Ù„ØªØ´ØºÙŠÙ„
CMD ["uvicorn", "api:app", "--host", "0.0.0.0", "--port", "8000"]
```

##### 2. **Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª ØºÙŠØ± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©**

```bash
# ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙØ¹Ù„ÙŠ
pip install pipreqs
pipreqs . --force

# Ù…Ù‚Ø§Ø±Ù†Ø© Ù…Ø¹ requirements.txt Ø§Ù„Ø­Ø§Ù„ÙŠ
```

### 3.2 Lazy Loading & Code Splitting

#### **ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø©:**

```python
# âŒ Ø§Ù„Ø­Ø§Ù„ÙŠ - ØªØ­Ù…ÙŠÙ„ ÙƒÙ„ Ø´ÙŠØ¡ Ø¹Ù†Ø¯ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
import streamlit as st
from export_utils import export_to_pdf, export_to_word
from video_processor import process_video_url
from image_processor import analyze_image_from_url

# âœ… ØªØ­Ø³ÙŠÙ† - Lazy Loading
import streamlit as st

# ØªØ­Ù…ÙŠÙ„ ÙÙ‚Ø· Ø¹Ù†Ø¯ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
if st.button("Export to PDF"):
    from export_utils import export_to_pdf
    export_to_pdf(...)

if st.button("Analyze Video"):
    from video_processor import process_video_url
    process_video_url(...)
```

### 3.3 ØªØ­Ø³ÙŠÙ† Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

#### **Ø§Ù„Ù…Ø´Ø§ÙƒÙ„ Ø§Ù„Ø­Ø§Ù„ÙŠØ©:**

```python
# âŒ N+1 Query Problem
analyses = get_recent_analyses(limit=10)
for analysis in analyses:
    # ÙƒÙ„ Ø¯ÙˆØ±Ø© ØªØ¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø±Ø© Ø£Ø®Ø±Ù‰!
    share_link = get_share_link(analysis.id)  # âŒ
```

#### **Ø§Ù„Ø­Ù„ÙˆÙ„:**

##### 1. **Eager Loading**

```python
# database.py
from sqlalchemy.orm import joinedload

def get_recent_analyses_optimized(limit: int = 10):
    db = SessionLocal()
    try:
        return db.query(AnalysisHistory) \
            .options(joinedload(AnalysisHistory.shares)) \
            .order_by(AnalysisHistory.created_at.desc()) \
            .limit(limit) \
            .all()
    finally:
        db.close()
```

##### 2. **Indexing**

```python
# database.py - Ø¥Ø¶Ø§ÙØ© Indexes
from sqlalchemy import Index

class AnalysisHistory(Base):
    __tablename__ = "analysis_history"
    
    id = Column(Integer, primary_key=True, index=True)
    url = Column(String, nullable=False, index=True)  # âœ… Index
    created_at = Column(DateTime, default=datetime.utcnow, index=True)  # âœ… Index
    
    # Composite Index Ù„Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ù…Ø±ÙƒØ¨Ø©
    __table_args__ = (
        Index('idx_url_created', 'url', 'created_at'),
    )
```

##### 3. **Query Caching**

```python
# database.py
from functools import lru_cache

@lru_cache(maxsize=100)
def get_analysis_by_id_cached(analysis_id: int):
    return get_analysis_by_id(analysis_id)
```

##### 4. **Pagination**

```python
# database.py
def get_analyses_paginated(page: int = 1, per_page: int = 20):
    db = SessionLocal()
    try:
        offset = (page - 1) * per_page
        
        total = db.query(AnalysisHistory).count()
        analyses = db.query(AnalysisHistory) \
            .order_by(AnalysisHistory.created_at.desc()) \
            .offset(offset) \
            .limit(per_page) \
            .all()
        
        return {
            'items': analyses,
            'total': total,
            'page': page,
            'per_page': per_page,
            'pages': (total + per_page - 1) // per_page
        }
    finally:
        db.close()
```

### 3.4 Ø¢Ù„ÙŠØ§Øª Caching Ù…ØªÙ‚Ø¯Ù…Ø©

#### **Ù†Ø¸Ø§Ù… Caching Ù…ØªØ¹Ø¯Ø¯ Ø§Ù„Ù…Ø³ØªÙˆÙŠØ§Øª:**

```python
# caching_strategy.py
import redis
import pickle
from functools import wraps

class CacheManager:
    def __init__(self):
        self.redis_client = redis.Redis(
            host=os.environ.get('REDIS_HOST', 'localhost'),
            port=int(os.environ.get('REDIS_PORT', 6379)),
            db=0,
            decode_responses=False  # Ù„Ù„Ø³Ù…Ø§Ø­ Ø¨Ù€ pickle
        )
        self.local_cache = {}  # L1 Cache
    
    def get(self, key: str):
        # Level 1: Local Memory Cache
        if key in self.local_cache:
            return self.local_cache[key]
        
        # Level 2: Redis Cache
        cached = self.redis_client.get(key)
        if cached:
            value = pickle.loads(cached)
            self.local_cache[key] = value  # ØªØ­Ø¯ÙŠØ« L1
            return value
        
        return None
    
    def set(self, key: str, value: any, ttl: int = 3600):
        # ØªØ®Ø²ÙŠÙ† ÙÙŠ L1
        self.local_cache[key] = value
        
        # ØªØ®Ø²ÙŠÙ† ÙÙŠ Redis
        self.redis_client.setex(
            key, 
            ttl, 
            pickle.dumps(value)
        )
    
    def cache_decorator(self, prefix: str, ttl: int = 3600):
        def decorator(func):
            @wraps(func)
            def wrapper(*args, **kwargs):
                # Ø¥Ù†Ø´Ø§Ø¡ cache key
                cache_key = f"{prefix}:{str(args)}:{str(kwargs)}"
                
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø­ØµÙˆÙ„ Ù…Ù† Cache
                cached = self.get(cache_key)
                if cached is not None:
                    return cached
                
                # ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯Ø§Ù„Ø©
                result = func(*args, **kwargs)
                
                # ØªØ®Ø²ÙŠÙ† Ø§Ù„Ù†ØªÙŠØ¬Ø©
                self.set(cache_key, result, ttl)
                
                return result
            return wrapper
        return decorator

# Ø§Ø³ØªØ®Ø¯Ø§Ù…
cache_manager = CacheManager()

@cache_manager.cache_decorator("content_analysis", ttl=7200)
def analyze_content_with_gemini(content: str, url: str):
    # ...
    pass
```

#### **Cache Warming Strategy**

```python
# cache_warmer.py
from celery import Celery

celery_app = Celery('tasks', broker='redis://localhost:6379/0')

@celery_app.task
def warm_popular_analyses():
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹ ÙÙŠ Cache"""
    popular_urls = db.query(AnalysisHistory.url) \
        .group_by(AnalysisHistory.url) \
        .order_by(func.count().desc()) \
        .limit(10) \
        .all()
    
    for url_tuple in popular_urls:
        url = url_tuple[0]
        # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙÙŠ Cache
        cache_manager.get_or_compute(f"analysis:{url}")

# Ø¬Ø¯ÙˆÙ„Ø© Ø§Ù„Ù…Ù‡Ù…Ø©
from celery.schedules import crontab

celery_app.conf.beat_schedule = {
    'warm-cache-every-hour': {
        'task': 'cache_warmer.warm_popular_analyses',
        'schedule': crontab(minute=0),  # ÙƒÙ„ Ø³Ø§Ø¹Ø©
    },
}
```

### 3.5 ØªØ­Ø³ÙŠÙ† ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ø£ØµÙˆÙ„

#### **Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Øª Ø§Ù„ØªØ­Ø³ÙŠÙ†:**

##### 1. **Image Compression**

```python
# image_optimizer.py
from PIL import Image
import io

def optimize_image(image_bytes: bytes, max_size: tuple = (800, 600), quality: int = 85) -> bytes:
    """
    Ø¶ØºØ· ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„ØµÙˆØ±
    """
    img = Image.open(io.BytesIO(image_bytes))
    
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ RGB Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
    if img.mode in ('RGBA', 'LA', 'P'):
        img = img.convert('RGB')
    
    # ØªØµØºÙŠØ± Ø§Ù„Ø­Ø¬Ù…
    img.thumbnail(max_size, Image.Resampling.LANCZOS)
    
    # Ø­ÙØ¸ Ù…Ø¹ Ø¶ØºØ·
    output = io.BytesIO()
    img.save(output, format='JPEG', quality=quality, optimize=True)
    
    return output.getvalue()
```

##### 2. **Lazy Image Loading ÙÙŠ Streamlit**

```python
# app.py
# âœ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ± Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø© ÙÙ‚Ø·
if st.checkbox("Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±"):
    with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±..."):
        images = extract_images_from_url(url)
        for img in images[:5]:  # Ø£ÙˆÙ„ 5 ØµÙˆØ± ÙÙ‚Ø·
            st.image(img['url'], use_column_width=True)
```

##### 3. **CDN Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙØµØ¯Ù‘Ø±Ø©**

```python
# export_utils.py
import boto3

s3_client = boto3.client('s3')

def upload_to_s3(file_path: str, bucket: str = 'your-bucket') -> str:
    """Ø±ÙØ¹ Ø§Ù„Ù…Ù„Ù Ø¥Ù„Ù‰ S3 ÙˆØ¥Ø±Ø¬Ø§Ø¹ CloudFront URL"""
    key = f"exports/{datetime.now().strftime('%Y/%m/%d')}/{os.path.basename(file_path)}"
    
    s3_client.upload_file(
        file_path,
        bucket,
        key,
        ExtraArgs={'ACL': 'public-read', 'ContentType': 'application/pdf'}
    )
    
    # CloudFront URL
    cdn_url = f"https://your-cdn-domain.cloudfront.net/{key}"
    return cdn_url

# Ø§Ø³ØªØ®Ø¯Ø§Ù…
pdf_path = export_to_pdf(analysis_data)
cdn_url = upload_to_s3(pdf_path)
st.success(f"ØªÙ… Ø§Ù„ØªØµØ¯ÙŠØ±: [ØªØ­Ù…ÙŠÙ„ PDF]({cdn_url})")
```

---

## 4. Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØªØ­ØªÙŠØ© ÙˆØ§Ù„Ù†Ø´Ø± (Infrastructure & Deployment)

### 4.1 Ø§Ø®ØªÙŠØ§Ø± Ø¨ÙŠØ¦Ø© Ø§Ù„Ø§Ø³ØªØ¶Ø§ÙØ©

#### **Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø©:**

| Ø§Ù„Ø¨ÙŠØ¦Ø© | Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª | Ø§Ù„Ø¹ÙŠÙˆØ¨ | Ø§Ù„ØªÙƒÙ„ÙØ© Ø§Ù„Ø´Ù‡Ø±ÙŠØ© Ø§Ù„ØªÙ‚Ø±ÙŠØ¨ÙŠØ© |
|--------|-----------|---------|---------------------------|
| **Replit (Ø§Ù„Ø­Ø§Ù„ÙŠ)** | - Ø³Ù‡ÙˆÙ„Ø© Ø§Ù„Ù†Ø´Ø±<br>- Ø¯Ø¹Ù… ÙÙ†ÙŠ Ø¬ÙŠØ¯<br>- PostgreSQL Ù…Ø¯Ù…Ø¬ | - Ù…Ø­Ø¯ÙˆØ¯ÙŠØ© Ø§Ù„Ù…ÙˆØ§Ø±Ø¯<br>- Ø£Ø¯Ø§Ø¡ Ù…ØªÙˆØ³Ø· | $20-50 |
| **AWS (EC2 + RDS)** | - Ù…Ø±ÙˆÙ†Ø© ÙƒØ§Ù…Ù„Ø©<br>- Ø£Ø¯Ø§Ø¡ Ø¹Ø§Ù„ÙŠ<br>- Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªÙˆØ³Ø¹ | - Ù…Ø¹Ù‚Ø¯ ÙÙŠ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯<br>- ÙŠØ­ØªØ§Ø¬ Ø®Ø¨Ø±Ø© | $50-200 |
| **Google Cloud Run** | - Serverless<br>- Auto-scaling<br>- ÙÙˆØªØ±Ø© Ø­Ø³Ø¨ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… | - Ù…Ø­Ø¯ÙˆØ¯ÙŠØ© ÙÙŠ Stateful apps | $30-100 |
| **DigitalOcean** | - Ø³Ù‡ÙˆÙ„Ø© Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯<br>- Ø£Ø³Ø¹Ø§Ø± Ø«Ø§Ø¨ØªØ©<br>- ÙˆØ«Ø§Ø¦Ù‚ Ù…Ù…ØªØ§Ø²Ø© | - Ù…ÙŠØ²Ø§Øª Ø£Ù‚Ù„ Ù…Ù† AWS | $40-120 |
| **Heroku** | - Ø³Ù‡Ù„ Ø¬Ø¯Ø§Ù‹<br>- Add-ons Ø¬Ø§Ù‡Ø²Ø© | - ØºØ§Ù„ÙŠ Ù†Ø³Ø¨ÙŠØ§Ù‹ | $50-150 |

#### **Ø§Ù„ØªÙˆØµÙŠØ© Ù„Ù„Ø¥Ù†ØªØ§Ø¬:**

```yaml
# Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£Ù…Ø«Ù„: AWS
Services:
  Compute:
    - ECS Fargate (Serverless Containers)
    - Auto Scaling: 2-10 instances
  
  Database:
    - RDS PostgreSQL (Multi-AZ)
    - Instance: db.t3.medium
  
  Cache:
    - ElastiCache Redis (cache.t3.micro)
  
  Storage:
    - S3 for exports and static files
    - CloudFront CDN
  
  Load Balancer:
    - Application Load Balancer (ALB)
  
  Monitoring:
    - CloudWatch Logs & Metrics
    - X-Ray for tracing
  
  Security:
    - VPC with private subnets
    - Security Groups
    - Secrets Manager
    - Certificate Manager (SSL/TLS)

Estimated Monthly Cost: $150-300
```

### 4.2 Ø¥Ø¹Ø¯Ø§Ø¯ CI/CD Pipeline

#### **GitHub Actions Workflow:**

```yaml
# .github/workflows/ci-cd.yml
name: CI/CD Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  # 1. Linting & Code Quality
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install black isort flake8 mypy
      
      - name: Run Black
        run: black --check .
      
      - name: Run isort
        run: isort --check-only .
      
      - name: Run Flake8
        run: flake8 .
      
      - name: Run MyPy
        run: mypy . --ignore-missing-imports

  # 2. Security Scan
  security:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Run Safety Check
        run: |
          pip install safety
          safety check --json
      
      - name: Run Bandit
        run: |
          pip install bandit
          bandit -r . -f json -o bandit-report.json
      
      - name: Upload Security Reports
        uses: actions/upload-artifact@v3
        with:
          name: security-reports
          path: |
            safety-report.json
            bandit-report.json

  # 3. Tests
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_password
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest pytest-cov pytest-asyncio
      
      - name: Run Tests
        env:
          DATABASE_URL: postgresql://test_user:test_password@localhost:5432/test_db
          REDIS_URL: redis://localhost:6379/0
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY_TEST }}
        run: |
          pytest --cov=. --cov-report=xml --cov-report=html
      
      - name: Upload Coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml

  # 4. Build Docker Image
  build:
    needs: [lint, security, test]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Login to DockerHub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}
      
      - name: Build and push
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: |
            myapp/content-analyzer:latest
            myapp/content-analyzer:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # 5. Deploy to Production (Main branch only)
  deploy:
    needs: [build]
    if: github.ref == 'refs/heads/main'
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to AWS ECS
        uses: aws-actions/amazon-ecs-deploy-task-definition@v1
        with:
          task-definition: ecs-task-definition.json
          service: content-analyzer-service
          cluster: production-cluster
          wait-for-service-stability: true
      
      - name: Notify Deployment
        uses: 8398a7/action-slack@v3
        with:
          status: ${{ job.status }}
          text: 'Deployment to production completed!'
          webhook_url: ${{ secrets.SLACK_WEBHOOK }}
```

### 4.3 Docker Containerization

#### **Dockerfile Ù…Ø­Ø³Ù‘Ù†:**

```dockerfile
# Dockerfile
FROM python:3.11-slim as base

# Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨Ù†Ø§Ø¡
ARG ENVIRONMENT=production

# ØªØ«Ø¨ÙŠØª dependencies Ø¹Ù„Ù‰ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù†Ø¸Ø§Ù…
RUN apt-get update && apt-get install -y \
    gcc \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø³ØªØ®Ø¯Ù… ØºÙŠØ± root
RUN useradd -m -u 1000 appuser

WORKDIR /app

# Ù†Ø³Ø® Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø£ÙˆÙ„Ø§Ù‹ (Ù„Ù„Ø§Ø³ØªÙØ§Ø¯Ø© Ù…Ù† Docker cache)
COPY requirements.txt .

# ØªØ«Ø¨ÙŠØª Python packages
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# Ù†Ø³Ø® Ø§Ù„ÙƒÙˆØ¯
COPY --chown=appuser:appuser . .

# Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØºÙŠØ± root
USER appuser

# Ø§Ù„Ù…Ù†Ø§ÙØ°
EXPOSE 8000 5000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Command
CMD ["sh", "-c", "uvicorn api:app --host 0.0.0.0 --port 8000 & streamlit run app.py --server.port 5000 --server.address 0.0.0.0"]
```

#### **Docker Compose Ù„Ù„ØªØ·ÙˆÙŠØ±:**

```yaml
# docker-compose.yml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "8000:8000"
      - "5000:5000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/content_analyzer
      - REDIS_URL=redis://redis:6379/0
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - GROQ_API_KEY=${GROQ_API_KEY}
      - ENVIRONMENT=development
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      - ./logs:/app/logs
  
  db:
    image: postgres:15-alpine
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=content_analyzer
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    ports:
      - "5432:5432"
  
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    ports:
      - "6379:6379"
  
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - ./ssl:/etc/nginx/ssl:ro
    depends_on:
      - app

volumes:
  postgres_data:
  redis_data:
```

### 4.4 Monitoring & Logging

#### **1. Centralized Logging (ELK Stack)**

```python
# logging_config.py
import logging
from logging.handlers import RotatingFileHandler
import json
from datetime import datetime

class JSONFormatter(logging.Formatter):
    def format(self, record):
        log_data = {
            'timestamp': datetime.utcnow().isoformat(),
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno
        }
        
        if record.exc_info:
            log_data['exception'] = self.formatException(record.exc_info)
        
        if hasattr(record, 'user_id'):
            log_data['user_id'] = record.user_id
        
        if hasattr(record, 'request_id'):
            log_data['request_id'] = record.request_id
        
        return json.dumps(log_data)

def setup_logging():
    logger = logging.getLogger()
    logger.setLevel(logging.INFO)
    
    # Console Handler
    console_handler = logging.StreamHandler()
    console_handler.setFormatter(JSONFormatter())
    logger.addHandler(console_handler)
    
    # File Handler with Rotation
    file_handler = RotatingFileHandler(
        'logs/app.log',
        maxBytes=10485760,  # 10MB
        backupCount=10
    )
    file_handler.setFormatter(JSONFormatter())
    logger.addHandler(file_handler)
    
    return logger

logger = setup_logging()
```

#### **2. Application Performance Monitoring (Sentry)**

```python
# monitoring.py
import sentry_sdk
from sentry_sdk.integrations.fastapi import FastApiIntegration
from sentry_sdk.integrations.sqlalchemy import SqlalchemyIntegration

def init_monitoring():
    sentry_sdk.init(
        dsn=os.environ.get("SENTRY_DSN"),
        integrations=[
            FastApiIntegration(),
            SqlalchemyIntegration(),
        ],
        traces_sample_rate=1.0 if os.environ.get("ENVIRONMENT") == "development" else 0.1,
        profiles_sample_rate=1.0,
        environment=os.environ.get("ENVIRONMENT", "production"),
        release=f"content-analyzer@{os.environ.get('APP_VERSION', '1.0.0')}",
    )

# ÙÙŠ api.py
from monitoring import init_monitoring
init_monitoring()
```

#### **3. Metrics Collection (Prometheus)**

```python
# metrics.py
from prometheus_client import Counter, Histogram, Gauge, generate_latest
from fastapi import Response

# Metrics
REQUEST_COUNT = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

REQUEST_DURATION = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration',
    ['method', 'endpoint']
)

ACTIVE_ANALYSES = Gauge(
    'active_analyses',
    'Number of active analyses'
)

CACHE_HIT_RATE = Counter(
    'cache_hits_total',
    'Total cache hits',
    ['cache_type']
)

# Middleware
from starlette.middleware.base import BaseHTTPMiddleware
import time

class PrometheusMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request, call_next):
        start_time = time.time()
        
        response = await call_next(request)
        
        duration = time.time() - start_time
        
        REQUEST_COUNT.labels(
            method=request.method,
            endpoint=request.url.path,
            status=response.status_code
        ).inc()
        
        REQUEST_DURATION.labels(
            method=request.method,
            endpoint=request.url.path
        ).observe(duration)
        
        return response

# ÙÙŠ api.py
app.add_middleware(PrometheusMiddleware)

@app.get("/metrics")
async def metrics():
    return Response(content=generate_latest(), media_type="text/plain")
```

### 4.5 Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ

#### **1. Database Backup Strategy**

```bash
#!/bin/bash
# backup_database.sh

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backups/postgres"
DB_NAME="content_analyzer"

# Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
pg_dump -h $DB_HOST -U $DB_USER -d $DB_NAME -F c -b -v -f "$BACKUP_DIR/backup_$DATE.dump"

# Ø±ÙØ¹ Ø¥Ù„Ù‰ S3
aws s3 cp "$BACKUP_DIR/backup_$DATE.dump" "s3://your-backup-bucket/postgres/$DATE.dump"

# Ø­Ø°Ù Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© (Ø£Ù‚Ø¯Ù… Ù…Ù† 30 ÙŠÙˆÙ…)
find $BACKUP_DIR -name "backup_*.dump" -mtime +30 -delete

# Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø¢Ø®Ø± 7 Ù†Ø³Ø® Ù…Ø­Ù„ÙŠØ©
ls -t $BACKUP_DIR/backup_*.dump | tail -n +8 | xargs rm -f

echo "Backup completed: $DATE"
```

#### **2. Scheduled Backups (Cron)**

```bash
# crontab -e

# Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ ÙŠÙˆÙ…ÙŠ ÙÙŠ 2 ØµØ¨Ø§Ø­Ø§Ù‹
0 2 * * * /opt/scripts/backup_database.sh >> /var/log/backup.log 2>&1

# Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø£Ø³Ø¨ÙˆØ¹ÙŠ ÙƒØ§Ù…Ù„ (Ø§Ù„Ø£Ø­Ø¯ 3 ØµØ¨Ø§Ø­Ø§Ù‹)
0 3 * * 0 /opt/scripts/full_backup.sh >> /var/log/backup.log 2>&1
```

#### **3. Disaster Recovery Plan**

```markdown
## Ø®Ø·Ø© Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„ÙƒÙˆØ§Ø±Ø«

### RTO (Recovery Time Objective): 2 Ø³Ø§Ø¹Ø©
### RPO (Recovery Point Objective): 24 Ø³Ø§Ø¹Ø©

### Ø®Ø·ÙˆØ§Øª Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø©:

1. **Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:**
   ```bash
   # ØªØ­Ù…ÙŠÙ„ Ø¢Ø®Ø± Ù†Ø³Ø®Ø© Ù…Ù† S3
   aws s3 cp s3://your-backup-bucket/postgres/latest.dump /tmp/
   
   # Ø§Ø³ØªØ¹Ø§Ø¯Ø©
   pg_restore -h $DB_HOST -U $DB_USER -d $DB_NAME -c /tmp/latest.dump
   ```

2. **Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚:**
   ```bash
   # Ø³Ø­Ø¨ Ø¢Ø®Ø± Ø¥ØµØ¯Ø§Ø±
   docker pull myapp/content-analyzer:latest
   
   # Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ´ØºÙŠÙ„
   docker-compose up -d
   ```

3. **Ø§Ù„ØªØ­Ù‚Ù‚:**
   ```bash
   # ÙØ­Øµ Ø§Ù„ØµØ­Ø©
   curl https://api.yourdomain.com/health
   
   # ÙØ­Øµ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
   psql -h $DB_HOST -U $DB_USER -d $DB_NAME -c "SELECT COUNT(*) FROM analysis_history;"
   ```
```

---

## 5. Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª (Testing)

### 5.1 Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ù‚ØªØ±Ø­Ø© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª

```
tests/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ conftest.py              # Fixtures Ù…Ø´ØªØ±ÙƒØ©
â”œâ”€â”€ unit/                    # Unit Tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_web_scraper.py
â”‚   â”œâ”€â”€ test_gemini_helper.py
â”‚   â”œâ”€â”€ test_database.py
â”‚   â”œâ”€â”€ test_cache_manager.py
â”‚   â””â”€â”€ test_validators.py
â”œâ”€â”€ integration/             # Integration Tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_api_endpoints.py
â”‚   â”œâ”€â”€ test_database_operations.py
â”‚   â””â”€â”€ test_ai_integration.py
â”œâ”€â”€ e2e/                     # End-to-End Tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_analysis_workflow.py
â”‚   â””â”€â”€ test_export_workflow.py
â”œâ”€â”€ performance/             # Performance Tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_load.py
â””â”€â”€ fixtures/                # Test Data
    â”œâ”€â”€ sample_html.html
    â”œâ”€â”€ sample_responses.json
    â””â”€â”€ test_urls.txt
```

### 5.2 Unit Tests (Ù…ÙÙ‚ÙˆØ¯ ØªÙ…Ø§Ù…Ø§Ù‹!)

#### **conftest.py - Fixtures Ù…Ø´ØªØ±ÙƒØ©:**

```python
# tests/conftest.py
import pytest
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from database import Base
import os

@pytest.fixture(scope="session")
def test_db_engine():
    """Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø®ØªØ¨Ø§Ø±"""
    engine = create_engine("sqlite:///:memory:")
    Base.metadata.create_all(engine)
    yield engine
    Base.metadata.drop_all(engine)

@pytest.fixture
def test_db_session(test_db_engine):
    """Ø¬Ù„Ø³Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
    SessionLocal = sessionmaker(bind=test_db_engine)
    session = SessionLocal()
    yield session
    session.rollback()
    session.close()

@pytest.fixture
def mock_gemini_client(monkeypatch):
    """Mock Ù„Ù€ Gemini API"""
    class MockResponse:
        text = "ØªØ­Ù„ÙŠÙ„ ØªØ¬Ø±ÙŠØ¨ÙŠ Ù„Ù„Ù…Ø­ØªÙˆÙ‰"
    
    def mock_generate(*args, **kwargs):
        return MockResponse()
    
    monkeypatch.setenv("GEMINI_API_KEY", "test-key-123")
    return mock_generate

@pytest.fixture
def sample_url():
    return "https://example.com/article"

@pytest.fixture
def sample_html():
    return """
    <html>
        <head><title>Ù…Ù‚Ø§Ù„ ØªØ¬Ø±ÙŠØ¨ÙŠ</title></head>
        <body>
            <article>
                <h1>Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ù‚Ø§Ù„</h1>
                <p>Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ù‚Ø§Ù„ Ù‡Ù†Ø§...</p>
                <pre><code>print("Hello World")</code></pre>
            </article>
        </body>
    </html>
    """
```

#### **test_web_scraper.py:**

```python
# tests/unit/test_web_scraper.py
import pytest
from web_scraper import extract_content_from_url, is_valid_url
from unittest.mock import patch, Mock

class TestURLValidation:
    def test_valid_http_url(self):
        assert is_valid_url("http://example.com") == True
    
    def test_valid_https_url(self):
        assert is_valid_url("https://example.com/article") == True
    
    def test_invalid_url_no_protocol(self):
        assert is_valid_url("example.com") == False
    
    def test_invalid_url_wrong_protocol(self):
        assert is_valid_url("ftp://example.com") == False
    
    @pytest.mark.parametrize("url,expected", [
        ("https://example.com", True),
        ("http://localhost:8000", True),
        ("https://192.168.1.1", True),
        ("javascript:alert(1)", False),
        ("", False),
    ])
    def test_url_validation_parametrized(self, url, expected):
        assert is_valid_url(url) == expected

class TestContentExtraction:
    @patch('web_scraper.trafilatura.fetch_url')
    @patch('web_scraper.trafilatura.extract')
    @patch('web_scraper.trafilatura.extract_metadata')
    def test_extract_content_success(
        self, 
        mock_metadata, 
        mock_extract, 
        mock_fetch,
        sample_html,
        sample_url
    ):
        # Setup mocks
        mock_fetch.return_value = sample_html
        mock_extract.return_value = "Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬"
        
        mock_meta = Mock()
        mock_meta.title = "Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ù‚Ø§Ù„"
        mock_meta.author = "Ø§Ù„ÙƒØ§ØªØ¨"
        mock_meta.date = "2025-11-10"
        mock_metadata.return_value = mock_meta
        
        # Execute
        result = extract_content_from_url(sample_url)
        
        # Assert
        assert result['url'] == sample_url
        assert result['title'] == "Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ù‚Ø§Ù„"
        assert result['main_content'] == "Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬"
        assert result['author'] == "Ø§Ù„ÙƒØ§ØªØ¨"
        assert result['has_code'] == True
        assert len(result['code_blocks']) > 0
    
    @patch('web_scraper.trafilatura.fetch_url')
    def test_extract_content_failure(self, mock_fetch, sample_url):
        mock_fetch.return_value = None
        
        with pytest.raises(Exception) as exc_info:
            extract_content_from_url(sample_url)
        
        assert "ÙØ´Ù„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰" in str(exc_info.value)
```

#### **test_database.py:**

```python
# tests/unit/test_database.py
import pytest
from database import save_analysis, get_analysis_by_id, get_recent_analyses
from datetime import datetime

class TestAnalysisCRUD:
    def test_save_analysis(self, test_db_session):
        analysis_id = save_analysis(
            url="https://example.com",
            title="Test Article",
            content_preview="Preview...",
            analysis_result="Analysis...",
            overall_rating=4.5,
            ai_provider="gemini"
        )
        
        assert analysis_id is not None
        assert isinstance(analysis_id, int)
    
    def test_get_analysis_by_id(self, test_db_session):
        # Create
        analysis_id = save_analysis(
            url="https://example.com",
            title="Test",
            content_preview="Preview",
            analysis_result="Result"
        )
        
        # Retrieve
        analysis = get_analysis_by_id(analysis_id)
        
        assert analysis is not None
        assert analysis.url == "https://example.com"
        assert analysis.title == "Test"
    
    def test_get_recent_analyses(self, test_db_session):
        # Create multiple
        for i in range(5):
            save_analysis(
                url=f"https://example.com/{i}",
                title=f"Article {i}",
                content_preview="Preview",
                analysis_result="Result"
            )
        
        # Retrieve
        recent = get_recent_analyses(limit=3)
        
        assert len(recent) == 3
        assert recent[0].url == "https://example.com/4"  # Most recent first
```

#### **test_cache_manager.py:**

```python
# tests/unit/test_cache_manager.py
import pytest
from cache_manager import set_cache, get_cache, clear_cache, cache_result
import time

class TestCacheOperations:
    def test_set_and_get_cache(self):
        key = "test_key"
        value = "test_value"
        
        set_cache(key, value)
        result = get_cache(key)
        
        assert result == value
    
    def test_cache_expiration(self):
        key = "expire_test"
        value = "value"
        
        set_cache(key, value, ttl=1)  # 1 second
        time.sleep(2)
        
        result = get_cache(key)
        assert result is None
    
    def test_clear_cache(self):
        set_cache("key1", "value1")
        set_cache("key2", "value2")
        
        clear_cache()
        
        assert get_cache("key1") is None
        assert get_cache("key2") is None
    
    def test_cache_decorator(self):
        call_count = 0
        
        @cache_result("test_func", ttl=60)
        def expensive_function(x):
            nonlocal call_count
            call_count += 1
            return x * 2
        
        result1 = expensive_function(5)
        result2 = expensive_function(5)
        
        assert result1 == 10
        assert result2 == 10
        assert call_count == 1  # Called only once, second from cache
```

### 5.3 Integration Tests

#### **test_api_endpoints.py:**

```python
# tests/integration/test_api_endpoints.py
import pytest
from fastapi.testclient import TestClient
from api import app
import os

@pytest.fixture
def client():
    return TestClient(app)

@pytest.fixture(autouse=True)
def setup_env(monkeypatch):
    monkeypatch.setenv("GEMINI_API_KEY", "test-key")
    monkeypatch.setenv("DATABASE_URL", "sqlite:///:memory:")

class TestHealthEndpoints:
    def test_root_endpoint(self, client):
        response = client.get("/")
        assert response.status_code == 200
        assert "status" in response.json()
        assert response.json()["status"] == "running"
    
    def test_health_check(self, client):
        response = client.get("/health")
        assert response.status_code == 200
        data = response.json()
        assert "status" in data
        assert "services" in data

class TestAnalysisEndpoints:
    def test_analyze_endpoint_valid_request(self, client):
        payload = {
            "url": "https://example.com/article",
            "ai_provider": "gemini",
            "analyze_images": False
        }
        
        with patch('api.analyze_content_with_gemini') as mock_analyze:
            mock_analyze.return_value = "ØªØ­Ù„ÙŠÙ„ ØªØ¬Ø±ÙŠØ¨ÙŠ"
            
            response = client.post("/analyze", json=payload)
            
            assert response.status_code == 200
            data = response.json()
            assert "success" in data
            assert data["success"] == True
    
    def test_analyze_endpoint_invalid_url(self, client):
        payload = {
            "url": "invalid-url",
            "ai_provider": "gemini"
        }
        
        response = client.post("/analyze", json=payload)
        assert response.status_code == 422  # Validation error
    
    def test_analyze_endpoint_rate_limit(self, client):
        payload = {
            "url": "https://example.com",
            "ai_provider": "gemini"
        }
        
        # Send 10 requests rapidly
        responses = [client.post("/analyze", json=payload) for _ in range(10)]
        
        # At least one should be rate limited
        status_codes = [r.status_code for r in responses]
        assert 429 in status_codes  # Too Many Requests

class TestExportEndpoints:
    def test_export_pdf(self, client):
        # First create an analysis
        analysis_id = 1  # Assume exists
        
        payload = {"analysis_id": analysis_id, "format": "pdf"}
        response = client.post("/export", json=payload)
        
        assert response.status_code == 200
        assert response.headers["content-type"] == "application/pdf"
```

### 5.4 End-to-End Tests

#### **test_analysis_workflow.py:**

```python
# tests/e2e/test_analysis_workflow.py
import pytest
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

@pytest.fixture(scope="module")
def browser():
    """Setup Selenium WebDriver"""
    options = webdriver.ChromeOptions()
    options.add_argument('--headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    
    driver = webdriver.Chrome(options=options)
    yield driver
    driver.quit()

class TestAnalysisWorkflow:
    def test_complete_analysis_flow(self, browser):
        # Navigate to app
        browser.get("http://localhost:5000")
        
        # Wait for page load
        wait = WebDriverWait(browser, 10)
        
        # Enter URL
        url_input = wait.until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "input[type='text']"))
        )
        url_input.send_keys("https://example.com/article")
        
        # Click analyze button
        analyze_btn = browser.find_element(By.XPATH, "//button[contains(text(), 'Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ù„ÙŠÙ„')]")
        analyze_btn.click()
        
        # Wait for results
        results = wait.until(
            EC.presence_of_element_located((By.CLASS_NAME, "analysis-results"))
        )
        
        assert results is not None
        assert "Ø§Ù„Ø´Ø±Ø­ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ" in browser.page_source
        
    def test_export_functionality(self, browser):
        browser.get("http://localhost:5000")
        wait = WebDriverWait(browser, 10)
        
        # Assume analysis is done
        # Click export button
        export_btn = wait.until(
            EC.element_to_be_clickable((By.XPATH, "//button[contains(text(), 'ØªØµØ¯ÙŠØ±')]"))
        )
        export_btn.click()
        
        # Select PDF format
        pdf_option = browser.find_element(By.XPATH, "//option[@value='pdf']")
        pdf_option.click()
        
        # Verify download initiated
        time.sleep(2)
        # Check download folder or response
```

### 5.5 Performance Tests

#### **test_load.py:**

```python
# tests/performance/test_load.py
from locust import HttpUser, task, between
import random

class ContentAnalyzerUser(HttpUser):
    wait_time = between(1, 3)
    
    @task(3)
    def analyze_content(self):
        urls = [
            "https://example.com/article1",
            "https://example.com/article2",
            "https://example.com/article3",
        ]
        
        payload = {
            "url": random.choice(urls),
            "ai_provider": "gemini",
            "analyze_images": False
        }
        
        self.client.post("/analyze", json=payload)
    
    @task(1)
    def get_recent_analyses(self):
        self.client.get("/analyses/recent?limit=10")
    
    @task(1)
    def health_check(self):
        self.client.get("/health")

# ØªØ´ØºÙŠÙ„:
# locust -f tests/performance/test_load.py --host=http://localhost:8000
```

### 5.6 Coverage Report

```bash
# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù…Ø¹ Coverage
pytest --cov=. --cov-report=html --cov-report=term-missing

# Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©:
# Name                    Stmts   Miss  Cover   Missing
# -----------------------------------------------------
# web_scraper.py            45      2    96%   23-24
# gemini_helper.py          32      1    97%   45
# database.py               67      3    96%   89-91
# api.py                   128      8    94%   145-152
# app.py                   234     47    80%   ...
# -----------------------------------------------------
# TOTAL                    856     68    92%
```

---

## 6. Ø§Ù„ØªÙˆØ«ÙŠÙ‚ (Documentation)

### 6.1 API Documentation (Swagger/OpenAPI)

#### **ØªØ­Ø³ÙŠÙ† Swagger Ø§Ù„Ø­Ø§Ù„ÙŠ:**

```python
# api.py - ØªØ­Ø³ÙŠÙ† Ø§Ù„ØªÙˆØ«ÙŠÙ‚
from fastapi import FastAPI
from fastapi.openapi.utils import get_openapi

def custom_openapi():
    if app.openapi_schema:
        return app.openapi_schema
    
    openapi_schema = get_openapi(
        title="Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ - API",
        version="2.0.0",
        description="""
        # Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©
        
        ÙˆØ§Ø¬Ù‡Ø© Ø¨Ø±Ù…Ø¬ÙŠØ© Ø´Ø§Ù…Ù„Ø© (REST API) Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.
        
        ## Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:
        - ğŸ” ØªØ­Ù„ÙŠÙ„ Ø°ÙƒÙŠ Ù„Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù†ØµÙŠ
        - ğŸ’» ÙƒØ´Ù ÙˆØ´Ø±Ø­ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©
        - ğŸ–¼ï¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… AI
        - ğŸ¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª Ù…Ù† YouTube
        - ğŸ“Š ØªÙ‚ÙŠÙŠÙ… Ù…ÙˆØ«ÙˆÙ‚ÙŠØ© Ø§Ù„Ù…ØµØ§Ø¯Ø±
        - ğŸ“¤ ØªØµØ¯ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª (PDF, Word, Markdown)
        - ğŸ”— Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª
        
        ## Ø§Ù„Ù…ØµØ§Ø¯Ù‚Ø©
        
        Ø­Ø§Ù„ÙŠØ§Ù‹ØŒ Ø§Ù„Ù€ API Ø¹Ø§Ù…. ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ØŒ Ø³ØªØ­ØªØ§Ø¬ Ø¥Ù„Ù‰:
        ```
        Authorization: Bearer <your_token>
        ```
        
        ## Ù…Ø¹Ø¯Ù„Ø§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
        
        - **Free Tier**: 10 Ø·Ù„Ø¨Ø§Øª/Ø¯Ù‚ÙŠÙ‚Ø©
        - **Pro Tier**: 100 Ø·Ù„Ø¨Ø§Øª/Ø¯Ù‚ÙŠÙ‚Ø©
        - **Enterprise**: ØºÙŠØ± Ù…Ø­Ø¯ÙˆØ¯
        
        ## Ø£Ù…Ø«Ù„Ø©
        
        ### ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰
        ```bash
        curl -X POST "https://api.yourdomain.com/analyze" \\
          -H "Content-Type: application/json" \\
          -d '{
            "url": "https://example.com/article",
            "ai_provider": "gemini"
          }'
        ```
        
        ## Ø±ÙˆØ§Ø¨Ø· Ù…ÙÙŠØ¯Ø©
        - [Ø§Ù„ØªÙˆØ«ÙŠÙ‚ Ø§Ù„ÙƒØ§Ù…Ù„](https://docs.yourdomain.com)
        - [Ø¯Ø¹Ù… ÙÙ†ÙŠ](https://support.yourdomain.com)
        - [GitHub](https://github.com/yourorg/content-analyzer)
        """,
        routes=app.routes,
        tags=[
            {
                "name": "Health",
                "description": "ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆØ§Ù„Ø®Ø¯Ù…Ø§Øª"
            },
            {
                "name": "Analysis",
                "description": "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø·"
            },
            {
                "name": "Export",
                "description": "ØªØµØ¯ÙŠØ± Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø¨ØµÙŠØº Ù…Ø®ØªÙ„ÙØ©"
            },
            {
                "name": "Share",
                "description": "Ù…Ø´Ø§Ø±ÙƒØ© Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª"
            },
            {
                "name": "History",
                "description": "Ø¥Ø¯Ø§Ø±Ø© Ø³Ø¬Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª"
            }
        ]
    )
    
    # Ø¥Ø¶Ø§ÙØ© Ø£Ù…Ø«Ù„Ø© Ù„Ù„Ù€ responses
    openapi_schema["paths"]["/analyze"]["post"]["responses"]["200"]["content"]["application/json"]["example"] = {
        "success": True,
        "analysis_id": 123,
        "url": "https://example.com/article",
        "title": "Ø¹Ù†ÙˆØ§Ù† Ø§Ù„Ù…Ù‚Ø§Ù„",
        "analysis": "Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªÙØµÙŠÙ„ÙŠ Ù‡Ù†Ø§...",
        "evaluation": {
            "overall_rating": 4.5,
            "credibility_score": 5,
            "quality_score": 4
        }
    }
    
    app.openapi_schema = openapi_schema
    return app.openapi_schema

app.openapi = custom_openapi
```

### 6.2 README Ø´Ø§Ù…Ù„

```markdown
# README.md

# ğŸ¤– Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª

[![Python Version](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.121-green.svg)](https://fastapi.tiangolo.com/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.51-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![Tests](https://github.com/yourorg/content-analyzer/workflows/tests/badge.svg)](https://github.com/yourorg/content-analyzer/actions)
[![Coverage](https://codecov.io/gh/yourorg/content-analyzer/branch/main/graph/badge.svg)](https://codecov.io/gh/yourorg/content-analyzer)

ØªØ·Ø¨ÙŠÙ‚ ÙˆÙŠØ¨ Ù…ØªÙ‚Ø¯Ù… Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ´Ø±Ø­ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ.

![Demo](docs/images/demo.gif)

## ğŸ“‹ Ø§Ù„Ù…Ø­ØªÙˆÙŠØ§Øª

- [Ø§Ù„Ù…ÙŠØ²Ø§Øª](#-Ø§Ù„Ù…ÙŠØ²Ø§Øª)
- [Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„ØªØ´ØºÙŠÙ„](#ï¸-Ù…ØªØ·Ù„Ø¨Ø§Øª-Ø§Ù„ØªØ´ØºÙŠÙ„)
- [Ø§Ù„ØªØ«Ø¨ÙŠØª](#-Ø§Ù„ØªØ«Ø¨ÙŠØª)
- [Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…](#-Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…)
- [API Documentation](#-api-documentation)
- [Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ©](#ï¸-Ø§Ù„Ø¨Ù†ÙŠØ©-Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ©)
- [Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª](#-Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª)
- [Ø§Ù„Ù†Ø´Ø±](#-Ø§Ù„Ù†Ø´Ø±)
- [Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø©](#-Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø©)
- [Ø§Ù„ØªØ±Ø®ÙŠØµ](#-Ø§Ù„ØªØ±Ø®ÙŠØµ)

## âœ¨ Ø§Ù„Ù…ÙŠØ²Ø§Øª

### ğŸ” Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ
- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø­ØªÙˆÙ‰ Ø´Ø§Ù…Ù„ Ù…Ù† Ø£ÙŠ Ø±Ø§Ø¨Ø·
- ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù†ØµÙˆØµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini/Groq AI
- ÙƒØ´Ù ÙˆØ´Ø±Ø­ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©
- ØªÙ‚ÙŠÙŠÙ… Ù…ÙˆØ«ÙˆÙ‚ÙŠØ© Ø§Ù„Ù…ØµØ§Ø¯Ø±
- Ø§Ù‚ØªØ±Ø§Ø­ Ù…Ø±Ø§Ø¬Ø¹ Ø¥Ø¶Ø§ÙÙŠØ© Ù…ÙˆØ«ÙˆÙ‚Ø©

### ğŸ¨ Ø§Ù„ÙˆØ³Ø§Ø¦Ø· Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø©
- ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini Vision
- ØªØ­Ù„ÙŠÙ„ ÙÙŠØ¯ÙŠÙˆÙ‡Ø§Øª YouTube
- Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØªØ±Ø¬Ù…Ø§Øª Ø§Ù„Ù†ØµÙŠØ©

### ğŸ“¤ Ø§Ù„ØªØµØ¯ÙŠØ± ÙˆØ§Ù„Ù…Ø´Ø§Ø±ÙƒØ©
- ØªØµØ¯ÙŠØ± PDF Ù…Ø¹ Ø¯Ø¹Ù… ÙƒØ§Ù…Ù„ Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©
- ØªØµØ¯ÙŠØ± Word (.docx) Ù…Ø¹ RTL
- ØªØµØ¯ÙŠØ± Markdown
- Ø±ÙˆØ§Ø¨Ø· Ù…Ø´Ø§Ø±ÙƒØ© Ù…Ø¹ QR codes

### ğŸš€ Ø§Ù„Ø£Ø¯Ø§Ø¡
- Ù†Ø¸Ø§Ù… Caching Ø°ÙƒÙŠ
- Ù…Ø¹Ø§Ù„Ø¬Ø© ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†Ø©
- Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª PostgreSQL
- REST API Ù…Ø¹ Swagger

## âš™ï¸ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„ØªØ´ØºÙŠÙ„

- Python 3.11+
- PostgreSQL 15+
- Redis 7+ (Ø§Ø®ØªÙŠØ§Ø±ÙŠØŒ Ù„Ù„Ù€ Caching)
- API Keys:
  - [Gemini API Key](https://makersuite.google.com/app/apikey)
  - [Groq API Key](https://console.groq.com/) (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)

## ğŸ“¦ Ø§Ù„ØªØ«Ø¨ÙŠØª

### 1. Clone Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹

\`\`\`bash
git clone https://github.com/yourorg/content-analyzer.git
cd content-analyzer
\`\`\`

### 2. Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©

\`\`\`bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# Ø£Ùˆ
venv\\Scripts\\activate  # Windows
\`\`\`

### 3. ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª

\`\`\`bash
pip install -r requirements.txt
\`\`\`

### 4. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦ÙŠØ©

\`\`\`bash
cp .env.example .env
# Ø¹Ø¯Ù‘Ù„ .env ÙˆØ£Ø¶Ù:
# GEMINI_API_KEY=your_key_here
# DATABASE_URL=postgresql://user:pass@localhost/dbname
\`\`\`

### 5. Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

\`\`\`bash
python -c "from database import init_db; init_db()"
\`\`\`

## ğŸš€ Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…

### ØªØ´ØºÙŠÙ„ Streamlit App

\`\`\`bash
streamlit run app.py --server.port 5000
\`\`\`

### ØªØ´ØºÙŠÙ„ FastAPI

\`\`\`bash
uvicorn api:app --host 0.0.0.0 --port 8000 --reload
\`\`\`

### ØªØ´ØºÙŠÙ„ ÙƒÙ„Ø§Ù‡Ù…Ø§ Ø¨Ù€ Docker

\`\`\`bash
docker-compose up
\`\`\`

## ğŸ“š API Documentation

Ø¨Ø¹Ø¯ ØªØ´ØºÙŠÙ„ FastAPIØŒ Ø§Ø°Ù‡Ø¨ Ø¥Ù„Ù‰:

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

### Ù…Ø«Ø§Ù„ Ø³Ø±ÙŠØ¹

\`\`\`bash
curl -X POST "http://localhost:8000/analyze" \\
  -H "Content-Type: application/json" \\
  -d '{
    "url": "https://example.com/article",
    "ai_provider": "gemini",
    "analyze_images": false
  }'
\`\`\`

## ğŸ—ï¸ Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„Ù…Ø¹Ù…Ø§Ø±ÙŠØ©

\`\`\`
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Streamlit UI  â”‚ â† ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
    â”‚ FastAPI â”‚ â† REST API
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Business Logic      â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ â€¢ web_scraper       â”‚
    â”‚ â€¢ gemini_helper     â”‚
    â”‚ â€¢ source_evaluator  â”‚
    â”‚ â€¢ cache_manager     â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
    â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ PostgreSQLâ”‚   â”‚  Redis   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
\`\`\`

## ğŸ§ª Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª

\`\`\`bash
# ØªØ´ØºÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª
pytest

# Ù…Ø¹ Coverage
pytest --cov=. --cov-report=html

# Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù…Ø­Ø¯Ø¯Ø©
pytest tests/unit/
pytest tests/integration/
pytest tests/e2e/

# Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø£Ø¯Ø§Ø¡
locust -f tests/performance/test_load.py
\`\`\`

## ğŸš€ Ø§Ù„Ù†Ø´Ø±

### Docker Production

\`\`\`bash
docker build -t content-analyzer:prod .
docker run -p 8000:8000 -p 5000:5000 content-analyzer:prod
\`\`\`

### AWS ECS

Ø±Ø§Ø¬Ø¹ [deployment/aws/README.md](deployment/aws/README.md)

### Kubernetes

Ø±Ø§Ø¬Ø¹ [deployment/k8s/README.md](deployment/k8s/README.md)

## ğŸ¤ Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø©

Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø§Øª Ù…Ø±Ø­Ø¨ Ø¨Ù‡Ø§! ÙŠØ±Ø¬Ù‰ Ø§ØªØ¨Ø§Ø¹ Ø§Ù„Ø®Ø·ÙˆØ§Øª:

1. Fork Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹
2. Ø¥Ù†Ø´Ø§Ø¡ branch Ù„Ù„Ù…ÙŠØ²Ø© (`git checkout -b feature/AmazingFeature`)
3. Commit Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª (`git commit -m 'Add AmazingFeature'`)
4. Push Ù„Ù„Ù€ Branch (`git push origin feature/AmazingFeature`)
5. ÙØªØ­ Pull Request

Ø±Ø§Ø¬Ø¹ [CONTRIBUTING.md](CONTRIBUTING.md) Ù„Ù„Ù…Ø²ÙŠØ¯.

## ğŸ“ Ø§Ù„ØªØ±Ø®ÙŠØµ

Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ù…Ø±Ø®Øµ ØªØ­Øª MIT License - Ø±Ø§Ø¬Ø¹ [LICENSE](LICENSE) Ù„Ù„ØªÙØ§ØµÙŠÙ„.

## ğŸ‘¥ Ø§Ù„ÙØ±ÙŠÙ‚

- **Ø§Ù„Ù…Ø·ÙˆØ± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ** - [Ø§Ø³Ù…Ùƒ](https://github.com/yourusername)

## ğŸ™ Ø´ÙƒØ± ÙˆØªÙ‚Ø¯ÙŠØ±

- [Streamlit](https://streamlit.io/) Ù„Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø§Ø¦Ø¹Ø©
- [FastAPI](https://fastapi.tiangolo.com/) Ù„Ù„Ù€ API Ø§Ù„Ø³Ø±ÙŠØ¹
- [Google Gemini](https://ai.google.dev/) Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
- [Trafilatura](https://trafilatura.readthedocs.io/) Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…Ø­ØªÙˆÙ‰

---

Made with â¤ï¸ in Saudi Arabia
\`\`\`
```

### 6.3 Contributing Guidelines

```markdown
# CONTRIBUTING.md

# Ø¯Ù„ÙŠÙ„ Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø©

Ø´ÙƒØ±Ø§Ù‹ Ù„Ø§Ù‡ØªÙ…Ø§Ù…Ùƒ Ø¨Ø§Ù„Ù…Ø³Ø§Ù‡Ù…Ø© ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹! ğŸ‰

## ğŸ“‹ Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡

1. ØªØ£ÙƒØ¯ Ù…Ù† Ù‚Ø±Ø§Ø¡Ø© [README.md](README.md)
2. Ø±Ø§Ø¬Ø¹ [Code of Conduct](CODE_OF_CONDUCT.md)
3. Ø§Ø¨Ø­Ø« ÙÙŠ [Issues](https://github.com/yourorg/content-analyzer/issues) Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©

## ğŸ”§ Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ¦Ø© Ø§Ù„ØªØ·ÙˆÙŠØ±ÙŠØ©

\`\`\`bash
# 1. Fork Ø§Ù„Ù…Ø³ØªÙˆØ¯Ø¹
git clone https://github.com/your-username/content-analyzer.git
cd content-analyzer

# 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø¨ÙŠØ¦Ø©
python -m venv venv
source venv/bin/activate
pip install -r requirements/development.txt

# 3. ØªØ«Ø¨ÙŠØª pre-commit hooks
pre-commit install
\`\`\`

## ğŸ¯ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ÙƒÙˆØ¯

### Python Style Guide

Ù†ØªØ¨Ø¹ [PEP 8](https://pep8.org/) Ù…Ø¹ Ø¨Ø¹Ø¶ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª:

- Ø·ÙˆÙ„ Ø§Ù„Ø³Ø·Ø± Ø§Ù„Ø£Ù‚ØµÙ‰: 100 Ø­Ø±Ù
- Ø§Ø³ØªØ®Ø¯Ø§Ù… Black Ù„Ù„ØªÙ†Ø³ÙŠÙ‚
- Type hints Ø¥Ù„Ø²Ø§Ù…ÙŠ
- Docstrings Ø¨Ø£Ø³Ù„ÙˆØ¨ Google

\`\`\`python
def analyze_content(url: str, provider: str = "gemini") -> Dict[str, Any]:
    """
    ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ù…Ù† Ø±Ø§Ø¨Ø·.

    Args:
        url: Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ù…Ø±Ø§Ø¯ ØªØ­Ù„ÙŠÙ„Ù‡Ø§
        provider: Ù…Ø­Ø±Ùƒ AI (gemini Ø£Ùˆ groq)

    Returns:
        Dict ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ­Ù„ÙŠÙ„

    Raises:
        ValueError: Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ØºÙŠØ± ØµØ­ÙŠØ­
    """
    pass
\`\`\`

### Commit Messages

Ù†Ø³ØªØ®Ø¯Ù… [Conventional Commits](https://www.conventionalcommits.org/):

\`\`\`
feat: Ø¥Ø¶Ø§ÙØ© Ù…ÙŠØ²Ø© ØªØµØ¯ÙŠØ± Excel
fix: Ø¥ØµÙ„Ø§Ø­ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±
docs: ØªØ­Ø¯ÙŠØ« README
test: Ø¥Ø¶Ø§ÙØ© Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù„Ù„Ù€ API
refactor: Ø¥Ø¹Ø§Ø¯Ø© Ù‡ÙŠÙƒÙ„Ø© web_scraper
perf: ØªØ­Ø³ÙŠÙ† Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù€ Cache
\`\`\`

## âœ… Ù‚Ø¨Ù„ Ø¥Ø±Ø³Ø§Ù„ Pull Request

1. **ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª:**
   \`\`\`bash
   pytest
   \`\`\`

2. **ÙØ­Øµ Ø§Ù„ÙƒÙˆØ¯:**
   \`\`\`bash
   black .
   isort .
   flake8 .
   mypy .
   \`\`\`

3. **Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Coverage:**
   \`\`\`bash
   pytest --cov=. --cov-report=term-missing
   # Coverage ÙŠØ¬Ø¨ Ø£Ù† ÙŠÙƒÙˆÙ† > 80%
   \`\`\`

4. **ØªØ­Ø¯ÙŠØ« Ø§Ù„ØªÙˆØ«ÙŠÙ‚** Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±

## ğŸ› Ø§Ù„Ø¥Ø¨Ù„Ø§Øº Ø¹Ù† Bugs

Ø§Ø³ØªØ®Ø¯Ù… [Issue Template](https://github.com/yourorg/content-analyzer/issues/new?template=bug_report.md)

\`\`\`markdown
**ÙˆØµÙ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©:**
ÙˆØµÙ ÙˆØ§Ø¶Ø­ ÙˆÙ…Ø®ØªØµØ±

**Ø®Ø·ÙˆØ§Øª Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø¥Ù†ØªØ§Ø¬:**
1. Ø§Ø°Ù‡Ø¨ Ø¥Ù„Ù‰ '...'
2. Ø§Ù†Ù‚Ø± Ø¹Ù„Ù‰ '...'
3. Ø­Ø¯Ø« Ø§Ù„Ø®Ø·Ø£

**Ø§Ù„Ø³Ù„ÙˆÙƒ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹:**
Ù…Ø§ Ø§Ù„Ø°ÙŠ ÙƒØ§Ù† ÙŠØ¬Ø¨ Ø£Ù† ÙŠØ­Ø¯Ø«

**Screenshots:**
Ø¥Ù† ÙˆØ¬Ø¯Øª

**Ø§Ù„Ø¨ÙŠØ¦Ø©:**
- OS: [e.g. Ubuntu 22.04]
- Python: [e.g. 3.11.5]
- Version: [e.g. 2.0.0]
\`\`\`

## ğŸ’¡ Ø§Ù‚ØªØ±Ø§Ø­ Ù…ÙŠØ²Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©

Ø§Ø³ØªØ®Ø¯Ù… [Feature Request Template](https://github.com/yourorg/content-analyzer/issues/new?template=feature_request.md)

## ğŸ“ Ù…Ø±Ø§Ø¬Ø¹Ø© Ø§Ù„ÙƒÙˆØ¯

Ø¬Ù…ÙŠØ¹ Pull Requests ØªÙ…Ø± Ø¨Ù…Ø±Ø§Ø¬Ø¹Ø©. Ø³Ù†ØªØ­Ù‚Ù‚ Ù…Ù†:

- âœ… Ø§Ù„ÙƒÙˆØ¯ ÙŠØªØ¨Ø¹ Ù…Ø¹Ø§ÙŠÙŠØ±Ù†Ø§
- âœ… Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª ØªÙ…Ø± Ø¨Ù†Ø¬Ø§Ø­
- âœ… Coverage ÙƒØ§ÙÙŠ (> 80%)
- âœ… Ø§Ù„ØªÙˆØ«ÙŠÙ‚ Ù…Ø­Ø¯Ù‘Ø«
- âœ… Ù„Ø§ security issues

## ğŸ“ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©

Ø±Ø§Ø¬Ø¹ [Projects](https://github.com/yourorg/content-analyzer/projects) Ù„Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª.

## â“ Ø£Ø³Ø¦Ù„Ø©

Ù„Ù„Ø£Ø³Ø¦Ù„Ø©ØŒ Ø§ÙØªØ­ [Discussion](https://github.com/yourorg/content-analyzer/discussions)
Ø£Ùˆ Ø±Ø§Ø³Ù„Ù†Ø§ Ø¹Ù„Ù‰: support@yourdomain.com

---

Ø´ÙƒØ±Ø§Ù‹ Ù„Ù…Ø³Ø§Ù‡Ù…ØªÙƒ! ğŸ™
\`\`\`
```

---

## 7. Ø®Ø·Ø© Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠØ©

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: Ø§Ù„Ø¥ØµÙ„Ø§Ø­Ø§Øª Ø§Ù„Ø­Ø±Ø¬Ø© (Ø£Ø³Ø¨ÙˆØ¹ 1-2)

#### **Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ø§Ù„Ù‚ØµÙˆÙ‰:**

| Ø§Ù„Ù…Ù‡Ù…Ø© | Ø§Ù„Ù…Ø¯Ø© | Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ | Ø§Ù„Ø­Ø§Ù„Ø© |
|--------|------|---------|--------|
| Ø¥ØµÙ„Ø§Ø­ Ø¬Ù…ÙŠØ¹ LSP Errors (15 Ø®Ø·Ø£) | 2 Ø£ÙŠØ§Ù… | Backend Dev | â³ |
| Ø¥Ø¶Ø§ÙØ© Ù†Ø¸Ø§Ù… Logging Ø´Ø§Ù…Ù„ | 1 ÙŠÙˆÙ… | Backend Dev | â³ |
| ØªØ£Ù…ÙŠÙ† CORS ÙÙŠ API | 4 Ø³Ø§Ø¹Ø§Øª | Backend Dev | â³ |
| Ø¥Ø¶Ø§ÙØ© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ø®Ø·Ø§Ø¡ Ø´Ø§Ù…Ù„Ø© | 2 Ø£ÙŠØ§Ù… | Backend Dev | â³ |
| Ø¥ØµÙ„Ø§Ø­ Ø§Ø¹ØªÙ…Ø§Ø¯ÙŠØ§Øª (pinning versions) | 4 Ø³Ø§Ø¹Ø§Øª | DevOps | â³ |

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Ø§Ù„Ø£Ù…Ø§Ù† ÙˆØ§Ù„Ù…ØµØ§Ø¯Ù‚Ø© (Ø£Ø³Ø¨ÙˆØ¹ 3-4)

| Ø§Ù„Ù…Ù‡Ù…Ø© | Ø§Ù„Ù…Ø¯Ø© | Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ | Ø§Ù„Ø­Ø§Ù„Ø© |
|--------|------|---------|--------|
| ØªØ·Ø¨ÙŠÙ‚ JWT Authentication | 3 Ø£ÙŠØ§Ù… | Backend Dev | â³ |
| Ø¥Ø¶Ø§ÙØ© Rate Limiting | 1 ÙŠÙˆÙ… | Backend Dev | â³ |
| Input Validation Ø´Ø§Ù…Ù„ | 2 Ø£ÙŠØ§Ù… | Backend Dev | â³ |
| Secrets Management (AWS Secrets Manager) | 2 Ø£ÙŠØ§Ù… | DevOps | â³ |
| Security Audit | 1 ÙŠÙˆÙ… | Security Team | â³ |

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 3: Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª (Ø£Ø³Ø¨ÙˆØ¹ 5-6)

| Ø§Ù„Ù…Ù‡Ù…Ø© | Ø§Ù„Ù…Ø¯Ø© | Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ | Ø§Ù„Ø­Ø§Ù„Ø© |
|--------|------|---------|--------|
| ÙƒØªØ§Ø¨Ø© Unit Tests (80+ tests) | 5 Ø£ÙŠØ§Ù… | QA + Backend | â³ |
| ÙƒØªØ§Ø¨Ø© Integration Tests (20+ tests) | 3 Ø£ÙŠØ§Ù… | QA | â³ |
| ÙƒØªØ§Ø¨Ø© E2E Tests (10+ scenarios) | 2 Ø£ÙŠØ§Ù… | QA | â³ |
| Ø¥Ø¹Ø¯Ø§Ø¯ CI/CD Pipeline | 2 Ø£ÙŠØ§Ù… | DevOps | â³ |
| ØªØ­Ù‚ÙŠÙ‚ Coverage > 80% | 3 Ø£ÙŠØ§Ù… | QA + Dev | â³ |

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 4: Ø§Ù„Ø£Ø¯Ø§Ø¡ ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ† (Ø£Ø³Ø¨ÙˆØ¹ 7-8)

| Ø§Ù„Ù…Ù‡Ù…Ø© | Ø§Ù„Ù…Ø¯Ø© | Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ | Ø§Ù„Ø­Ø§Ù„Ø© |
|--------|------|---------|--------|
| ØªØ·Ø¨ÙŠÙ‚ Redis Caching | 2 Ø£ÙŠØ§Ù… | Backend Dev | â³ |
| ØªØ­Ø³ÙŠÙ† Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª DB (Indexing) | 1 ÙŠÙˆÙ… | Backend Dev | â³ |
| Async/Await ÙÙŠ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª | 3 Ø£ÙŠØ§Ù… | Backend Dev | â³ |
| CDN Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø«Ø§Ø¨ØªØ© | 1 ÙŠÙˆÙ… | DevOps | â³ |
| Load Testing (1000+ concurrent) | 2 Ø£ÙŠØ§Ù… | Performance Team | â³ |

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 5: Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØªØ­ØªÙŠØ© ÙˆØ§Ù„Ù†Ø´Ø± (Ø£Ø³Ø¨ÙˆØ¹ 9-10)

| Ø§Ù„Ù…Ù‡Ù…Ø© | Ø§Ù„Ù…Ø¯Ø© | Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ | Ø§Ù„Ø­Ø§Ù„Ø© |
|--------|------|---------|--------|
| Ø¥Ø¹Ø¯Ø§Ø¯ AWS Infrastructure | 3 Ø£ÙŠØ§Ù… | DevOps | â³ |
| Dockerization & Orchestration | 2 Ø£ÙŠØ§Ù… | DevOps | â³ |
| Monitoring (Prometheus + Grafana) | 2 Ø£ÙŠØ§Ù… | DevOps | â³ |
| Logging (ELK Stack) | 2 Ø£ÙŠØ§Ù… | DevOps | â³ |
| Backup Strategy | 1 ÙŠÙˆÙ… | DevOps | â³ |
| Disaster Recovery Plan | 1 ÙŠÙˆÙ… | DevOps + Team Lead | â³ |

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 6: Ø§Ù„ØªÙˆØ«ÙŠÙ‚ ÙˆØ§Ù„ØªØ¯Ø±ÙŠØ¨ (Ø£Ø³Ø¨ÙˆØ¹ 11)

| Ø§Ù„Ù…Ù‡Ù…Ø© | Ø§Ù„Ù…Ø¯Ø© | Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ | Ø§Ù„Ø­Ø§Ù„Ø© |
|--------|------|---------|--------|
| ØªØ­Ø¯ÙŠØ« API Documentation | 2 Ø£ÙŠØ§Ù… | Tech Writer | â³ |
| ÙƒØªØ§Ø¨Ø© User Guide | 2 Ø£ÙŠØ§Ù… | Tech Writer | â³ |
| ÙƒØªØ§Ø¨Ø© Deployment Guide | 1 ÙŠÙˆÙ… | DevOps + Writer | â³ |
| ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙØ±ÙŠÙ‚ | 1 ÙŠÙˆÙ… | Team Lead | â³ |

### Ø§Ù„Ù…Ø±Ø­Ù„Ø© 7: Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙˆØ§Ù„Ù†Ø´Ø± (Ø£Ø³Ø¨ÙˆØ¹ 12)

| Ø§Ù„Ù…Ù‡Ù…Ø© | Ø§Ù„Ù…Ø¯Ø© | Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ | Ø§Ù„Ø­Ø§Ù„Ø© |
|--------|------|---------|--------|
| UAT (User Acceptance Testing) | 3 Ø£ÙŠØ§Ù… | QA + Stakeholders | â³ |
| Security Penetration Testing | 2 Ø£ÙŠØ§Ù… | Security Team | â³ |
| Performance Testing ÙÙŠ Staging | 1 ÙŠÙˆÙ… | Performance Team | â³ |
| Final Review & Approvals | 1 ÙŠÙˆÙ… | All Teams | â³ |
| Production Deployment | 1 ÙŠÙˆÙ… | DevOps + All | â³ |
| Post-Deployment Monitoring | Ù…Ø³ØªÙ…Ø± | DevOps | â³ |

---

## ğŸ“Š Ù…Ù„Ø®Øµ Ø§Ù„ØªÙ‚Ø¯ÙŠØ±Ø§Øª

### Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: 12 Ø£Ø³Ø¨ÙˆØ¹ (3 Ø£Ø´Ù‡Ø±)

### Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¨Ø´Ø±ÙŠØ© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©:
- **Backend Developer**: 1-2 Ù…Ø·ÙˆØ±ÙŠÙ†
- **DevOps Engineer**: 1 Ù…Ù‡Ù†Ø¯Ø³
- **QA Engineer**: 1-2 Ù…Ø®ØªØ¨Ø±ÙŠÙ†
- **Security Specialist**: 1 (Ø¨Ø¯ÙˆØ§Ù… Ø¬Ø²Ø¦ÙŠ)
- **Tech Writer**: 1 (Ø¨Ø¯ÙˆØ§Ù… Ø¬Ø²Ø¦ÙŠ)
- **Team Lead/Architect**: 1

### Ø§Ù„ØªÙƒÙ„ÙØ© Ø§Ù„ØªÙ‚Ø¯ÙŠØ±ÙŠØ©:

| Ø§Ù„Ø¨Ù†Ø¯ | Ø§Ù„ØªÙƒÙ„ÙØ© Ø§Ù„Ø´Ù‡Ø±ÙŠØ© (USD) |
|-------|----------------------|
| **Infrastructure (AWS)** | $200-400 |
| **Third-party Services** |  |
| - Gemini API | $100-500 |
| - Monitoring (Sentry) | $50 |
| - CDN (CloudFront) | $20-100 |
| **Personnel** | $15,000-25,000 |
| **Miscellaneous** | $500 |
| **Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø´Ù‡Ø±ÙŠ** | **$16,000-26,500** |
| **Ø¥Ø¬Ù…Ø§Ù„ÙŠ 3 Ø£Ø´Ù‡Ø±** | **$48,000-80,000** |

---

## ğŸ¯ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ù†Ø¬Ø§Ø­ (KPIs)

### Ø§Ù„Ø£Ù…Ø§Ù†:
- âœ… 0 Ø«ØºØ±Ø§Øª Ø£Ù…Ù†ÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ø§Ù„Ø®Ø·ÙˆØ±Ø©
- âœ… Ø¬Ù…ÙŠØ¹ Endpoints Ù…Ø­Ù…ÙŠØ© Ø¨Ù€ Authentication
- âœ… Rate Limiting Ù…ÙØ¹Ù‘Ù„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ APIs

### Ø§Ù„Ø¬ÙˆØ¯Ø©:
- âœ… Code Coverage > 80%
- âœ… 0 LSP Errors
- âœ… Ø¬Ù…ÙŠØ¹ Tests ØªÙ…Ø± Ø¨Ù†Ø¬Ø§Ø­

### Ø§Ù„Ø£Ø¯Ø§Ø¡:
- âœ… Response Time < 2 Ø«Ø§Ù†ÙŠØ© (p95)
- âœ… Ø¯Ø¹Ù… 1000+ concurrent users
- âœ… Uptime > 99.5%

### Ø§Ù„ØªÙˆØ«ÙŠÙ‚:
- âœ… API Documentation ÙƒØ§Ù…Ù„ ÙˆÙ…Ø­Ø¯Ù‘Ø«
- âœ… README Ø´Ø§Ù…Ù„
- âœ… Deployment Guide Ø¬Ø§Ù‡Ø²

---

## ğŸš¨ Ø§Ù„Ù…Ø®Ø§Ø·Ø± ÙˆØ§Ù„ØªØ­Ø¯ÙŠØ§Øª

### Ù…Ø®Ø§Ø·Ø± ØªÙ‚Ù†ÙŠØ©:

1. **API Rate Limits Ù…Ù† Gemini/Groq**
   - **Ø§Ù„Ø­Ù„**: Ø§Ø³ØªØ®Ø¯Ø§Ù… Caching aggressively + Ù†Ø¸Ø§Ù… queue

2. **ØªÙƒÙ„ÙØ© AI APIs Ù…Ø±ØªÙØ¹Ø©**
   - **Ø§Ù„Ø­Ù„**: Caching + ØªØ­Ø¯ÙŠØ¯ quotas Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…ÙŠÙ†

3. **Ø£Ø¯Ø§Ø¡ Streamlit ÙÙŠ Production**
   - **Ø§Ù„Ø­Ù„**: Ø§Ø³ØªØ®Ø¯Ø§Ù… Streamlit Cloud Ø£Ùˆ containerization Ù…Ø­Ø³Ù‘Ù†

### Ù…Ø®Ø§Ø·Ø± Ù…Ø´Ø±ÙˆØ¹:

1. **Timeline Ø¶ÙŠÙ‚**
   - **Ø§Ù„Ø­Ù„**: ØªØ­Ø¯ÙŠØ¯ Ø£ÙˆÙ„ÙˆÙŠØ§Øª ÙˆØ§Ø¶Ø­Ø© + agile sprints

2. **Ù†Ù‚Øµ Ø§Ù„Ø®Ø¨Ø±Ø© ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ù…Ø¬Ø§Ù„Ø§Øª**
   - **Ø§Ù„Ø­Ù„**: Ø§Ø³ØªØ´Ø§Ø±Ø§Øª Ø®Ø§Ø±Ø¬ÙŠØ© + ØªØ¯Ø±ÙŠØ¨

---

## âœ… Checklist Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ù†ØªØ§Ø¬

### Ø§Ù„Ø£Ù…Ø§Ù†:
- [ ] Ø¬Ù…ÙŠØ¹ endpoints Ù…Ø­Ù…ÙŠØ© Ø¨Ù€ Authentication
- [ ] Rate limiting Ù…ÙØ¹Ù‘Ù„
- [ ] CORS Ù…Ù‚ÙŠÙ‘Ø¯
- [ ] Input validation Ø´Ø§Ù…Ù„
- [ ] Secrets ÙÙŠ Secrets Manager
- [ ] HTTPS Ø¥Ù„Ø²Ø§Ù…ÙŠ
- [ ] Security headers (CSP, HSTS, etc.)
- [ ] Penetration testing Ù…ÙƒØªÙ…Ù„

### Ø§Ù„Ø£Ø¯Ø§Ø¡:
- [ ] Redis Caching Ù…ÙØ¹Ù‘Ù„
- [ ] Database indexes Ù…Ø­Ø³Ù‘Ù†Ø©
- [ ] CDN Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø«Ø§Ø¨ØªØ©
- [ ] Async operations
- [ ] Load testing Ù†Ø§Ø¬Ø­ (1000+ users)

### Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª:
- [ ] Unit tests coverage > 80%
- [ ] Integration tests Ù…ÙˆØ¬ÙˆØ¯Ø©
- [ ] E2E tests Ù…ÙˆØ¬ÙˆØ¯Ø©
- [ ] Ø¬Ù…ÙŠØ¹ Tests ØªÙ…Ø± ÙÙŠ CI/CD

### Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©:
- [ ] Logging Ø´Ø§Ù…Ù„ (ELK/CloudWatch)
- [ ] Monitoring (Prometheus/Grafana)
- [ ] Error tracking (Sentry)
- [ ] Alerting Ù…ÙØ¹Ø¯Ù‘

### Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ:
- [ ] Database backup ÙŠÙˆÙ…ÙŠ
- [ ] Backup testing Ù…ÙÙ†ÙÙ‘Ø°
- [ ] Disaster recovery plan Ù…ÙˆØ«Ù‘Ù‚

### Ø§Ù„ØªÙˆØ«ÙŠÙ‚:
- [ ] API Documentation ÙƒØ§Ù…Ù„
- [ ] README Ù…Ø­Ø¯Ù‘Ø«
- [ ] Deployment guide Ø¬Ø§Ù‡Ø²
- [ ] Runbooks Ù„Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©

### Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØªØ­ØªÙŠØ©:
- [ ] Docker images Ù…Ø­Ø³Ù‘Ù†Ø©
- [ ] CI/CD pipeline ÙŠØ¹Ù…Ù„
- [ ] Auto-scaling Ù…ÙØ¹Ø¯Ù‘
- [ ] Health checks Ù…ÙˆØ¬ÙˆØ¯Ø©
- [ ] SSL/TLS certificates ØµØ§Ù„Ø­Ø©

---

## ğŸ“ Ø¬Ù‡Ø§Øª Ø§Ù„Ø§ØªØµØ§Ù„

| Ø§Ù„Ø¯ÙˆØ± | Ø§Ù„Ø§Ø³Ù… | Ø§Ù„Ø¨Ø±ÙŠØ¯ Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠ |
|------|------|-------------------|
| **Project Lead** | [Name] | lead@yourdomain.com |
| **Backend Lead** | [Name] | backend@yourdomain.com |
| **DevOps Lead** | [Name] | devops@yourdomain.com |
| **QA Lead** | [Name] | qa@yourdomain.com |

---

## ğŸ“š Ù…Ø±Ø§Ø¬Ø¹ Ø¥Ø¶Ø§ÙÙŠØ©

- [FastAPI Best Practices](https://fastapi.tiangolo.com/tutorial/)
- [Streamlit Production Deployment](https://docs.streamlit.io/streamlit-cloud)
- [PostgreSQL Performance Tuning](https://wiki.postgresql.org/wiki/Performance_Optimization)
- [AWS Well-Architected Framework](https://aws.amazon.com/architecture/well-architected/)
- [OWASP Top 10](https://owasp.org/www-project-top-ten/)

---

**ØªØ§Ø±ÙŠØ® Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ±:** 10 Ù†ÙˆÙÙ…Ø¨Ø± 2025  
**Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«:** 10 Ù†ÙˆÙÙ…Ø¨Ø± 2025  
**Ø§Ù„Ø¥ØµØ¯Ø§Ø±:** 1.0  
**Ø§Ù„Ø­Ø§Ù„Ø©:** Ù…Ø³ÙˆØ¯Ø© Ù„Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©

---

Â© 2025 Content Analyzer Team. All rights reserved.
